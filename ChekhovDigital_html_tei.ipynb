{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Кудин_Chekhov_Digital_HTML-TEI.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz46TQKsaaUW"
      },
      "source": [
        "Для обработки опубликованных и изданных текстов А. П. Чехова. При обработке неизданных/неопубликованных документов в исходном файле (TEIdoc) изменить информацию внутри тегов \"isFinished\" (оконченные/неокончнные) и \"isPublished\" (опубликованные/неопубликованные).\r\n",
        "\r\n",
        "Исходные HTML-файлы должны быть размещены на гугл-диске (если они расположены в другом месте, поменять директорию. Переменные directory, new_directory).\r\n",
        "\r\n",
        "При обработке томов, содержащих только один жанр текста (например, том 11 - пьесы) заполнить в исходном файле (TEIdoc) тег \"textClass\" (тип текста)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-cd0OJ1hICV",
        "outputId": "e5b86ba5-deee-49e4-bafa-df948722bcf1"
      },
      "source": [
        "from bs4 import BeautifulSoup\r\n",
        "import re\r\n",
        "!pip install natasha\r\n",
        "import os\r\n",
        "\r\n",
        "# Для документов, расположенных на гугл-диске\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting natasha\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/8e/ab0745100be276750fb6b8858c6180a1756696572295a74eb5aea77f3bbd/natasha-1.4.0-py3-none-any.whl (34.4MB)\n",
            "\u001b[K     |████████████████████████████████| 34.4MB 112kB/s \n",
            "\u001b[?25hCollecting yargy>=0.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/46/bc1a17200a55f4b0608f39ac64f1840fd4a52f9eeea462d9afecbf71246b/yargy-0.15.0-py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.8MB/s \n",
            "\u001b[?25hCollecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/57/b2ff2fae3376d4f3c697b9886b64a54b476e1a332c67eee9f88e7f1ae8c9/pymorphy2-0.9.1-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.8MB/s \n",
            "\u001b[?25hCollecting navec>=0.9.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/c1/771ec5565f0ce24874d7fd325b429f9caa80517a40d2e4ce5705120591f3/navec-0.10.0-py3-none-any.whl\n",
            "Collecting slovnet>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/3b/f1ef495be8990004959dd0510c95f688d1b07529f6a862bc56a405770b26/slovnet-0.5.0-py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.2MB/s \n",
            "\u001b[?25hCollecting razdel>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/15/2c/664223a3924aa6e70479f7d37220b3a658765b9cfe760b4af7ffdc50d38f/razdel-0.5.0-py3-none-any.whl\n",
            "Collecting ipymarkup>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bf/9b/bf54c98d50735a4a7c84c71e92c5361730c878ebfe903d2c2d196ef66055/ipymarkup-0.9.0-py3-none-any.whl\n",
            "Collecting dawg-python>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2->natasha) (0.6.2)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 35.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from navec>=0.9.0->natasha) (1.19.5)\n",
            "Collecting intervaltree>=3\n",
            "  Downloading https://files.pythonhosted.org/packages/50/fb/396d568039d21344639db96d940d40eb62befe704ef849b27949ded5c3bb/intervaltree-3.1.0.tar.gz\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.6/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.3.0)\n",
            "Building wheels for collected packages: intervaltree\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26102 sha256=dcdbffa771721ae8b6d6ea51b26cc7fe10268368984f99193d1918a564ecb76f\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/f2/66/e9c30d3e9499e65ea2fa0d07c002e64de63bd0adaa49c445bf\n",
            "Successfully built intervaltree\n",
            "Installing collected packages: dawg-python, pymorphy2-dicts-ru, pymorphy2, yargy, navec, razdel, slovnet, intervaltree, ipymarkup, natasha\n",
            "  Found existing installation: intervaltree 2.1.0\n",
            "    Uninstalling intervaltree-2.1.0:\n",
            "      Successfully uninstalled intervaltree-2.1.0\n",
            "Successfully installed dawg-python-0.7.2 intervaltree-3.1.0 ipymarkup-0.9.0 natasha-1.4.0 navec-0.10.0 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844 razdel-0.5.0 slovnet-0.5.0 yargy-0.15.0\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnvquLWQ_TY7",
        "outputId": "0435418a-9cc4-4706-8dc4-7265e867bb45"
      },
      "source": [
        "your_name = input('Введите свое ФИО в творительном падеже') # Заполняем имя того, кто преобразовывал файлы HTML в TEI"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Введите свое ФИО в творительном падежеКудин Анастасией\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G58OOEktKoEN"
      },
      "source": [
        "iter = 1 # Для нумерации текстов в названии файлов TEI\r\n",
        "\r\n",
        "directory = 'drive/My Drive/Texts/3/' # Папка с файлами HTML\r\n",
        "new_directory = 'drive/My Drive/Texts_tei/3/' # Папка для документов TEI\r\n",
        "\r\n",
        "for filename in os.listdir(directory):\r\n",
        "\r\n",
        "    file_html = open(directory + filename,'r',encoding='windows-1251')\r\n",
        "    content = file_html.read()\r\n",
        "    file_html.close()\r\n",
        "    soup_html = BeautifulSoup(content, 'html.parser')\r\n",
        "\r\n",
        "    file_tei = open('TEIdoc.xml','r',encoding='utf8') # Указать адрес исходного документа TEI\r\n",
        "    content = file_tei.read()\r\n",
        "    file_tei.close()\r\n",
        "    soup_tei = BeautifulSoup(content, 'html.parser')\r\n",
        "\r\n",
        "    notes_html = open('Notes3.html','r',encoding='windows-1251') # Указать адрес документа с примечаниями к обрабатываемому тому\r\n",
        "    content1 = notes_html.read()\r\n",
        "    notes_html.close()\r\n",
        "    soup_notes_html = BeautifulSoup(content1, 'html.parser')\r\n",
        "\r\n",
        "    # Заполняем заголовок\r\n",
        "    title_main_tei = soup_tei.find('title')\r\n",
        "    title_tag_html = soup_html.find_all('meta', attrs={'name':'title'})\r\n",
        "    if len(title_tag_html) == 2: # Если есть подзаголовок\r\n",
        "        title_main_tei.string = title_tag_html[0].get('content') + ' (' + title_tag_html[1].get('content') + ')'\r\n",
        "    else:\r\n",
        "        title_main_tei.string = title_tag_html[0].get('content')\r\n",
        "\r\n",
        "    # Заполняем описание текста\r\n",
        "    description_html = soup_html.find('div', class_='description')\r\n",
        "    full_bibl = soup_tei.find('biblfull').find('p')\r\n",
        "    description_html = soup_html.find('div', class_='description')\r\n",
        "    full_bibl.string = description_html.text\r\n",
        "\r\n",
        "    # Заполняем имя того, кто преобразовал текст в TEI\r\n",
        "    resp_stmt = soup_tei.find('respstmt')\r\n",
        "    name_resp_stmt = resp_stmt.find('persname')\r\n",
        "    name_resp_stmt.string = your_name\r\n",
        "\r\n",
        "    # Заполняем информацию об объеме произведения\r\n",
        "    extent_inf = soup_tei.find('extent')\r\n",
        "\r\n",
        "    list_ids = [] # Получаем список номеров страниц\r\n",
        "    for tag in soup_html.find_all('span', class_='page') :\r\n",
        "        tag_page=tag.get('id')\r\n",
        "        list_ids.append(tag_page[2:])\r\n",
        "\r\n",
        "    # Считаем объем\r\n",
        "    volume = int(list_ids[-1]) - int(list_ids[0]) + 1\r\n",
        "    volume_str = str(volume)\r\n",
        "\r\n",
        "    # Заполняем информацию об объеме в тексте\r\n",
        "    if volume_str[-1] == '5' or volume_str[-1] == '6' or volume_str[-1] == '7' or volume_str[-1] == '8' or volume_str[-1] == '9' or volume_str[-1] == '0' or volume_str[-2:] == '11' or volume_str[-2:] == '12' or volume_str[-2:] == '13' or volume_str[-2:] == '14' or volume_str[-2:] == '15' or volume_str[-2:] == '16' or volume_str[-2:] == '17' or volume_str[-2:] == '18' or volume_str[-2:] == '19':\r\n",
        "        volume_f = volume_str + ' страниц'\r\n",
        "    elif volume_str[-1] == '1':\r\n",
        "        volume_f = volume_str + ' страница'\r\n",
        "    elif volume_str[-1] == '2' or volume_str[-1] == '3' or volume_str[-1] == '4':\r\n",
        "        volume_f = volume_str + ' страницы'\r\n",
        "\r\n",
        "    # Заполняем информацию об объеме в атрибутах тегов\r\n",
        "    tag_measure = soup_tei.new_tag('measure') \r\n",
        "    extent_inf.insert(0, tag_measure)\r\n",
        "\r\n",
        "    soup_tei.find('measure')['unit'] = 'pages'\r\n",
        "    soup_tei.find('measure')['quantity'] = volume_str\r\n",
        "\r\n",
        "    measure_inf = soup_tei.find('measure')\r\n",
        "    measure_inf.string = volume_f\r\n",
        "\r\n",
        "    # Заполняем дату публикации\r\n",
        "    publ_date = soup_tei.find('publicationstmt')\r\n",
        "    publ_date1 = publ_date.find('date')\r\n",
        "    date_1 = soup_html.find('meta', attrs={'name':'date'})\r\n",
        "    publ_date1.string = date_1.get('content')\r\n",
        "    publ_date.find('date')['when'] = date_1.get('content')\r\n",
        "\r\n",
        "    # И дату создания\r\n",
        "    date_cr = soup_tei.find('creation').find('date')\r\n",
        "    creation = soup_tei.find('creation')\r\n",
        "    abz = description_html.find_all('p')\r\n",
        "    search = abz[-2].text\r\n",
        "\r\n",
        "    date_from_to = re.findall(r'\\d{4}—\\d{4}', search)\r\n",
        "    if len(date_from_to)>0: # Если том создавался несколько лет\r\n",
        "        date_cr1 = date_from_to\r\n",
        "        date_cr.string = date_cr1[0]\r\n",
        "        creation.find('date')['from'] = date_cr1[0][:4]\r\n",
        "        creation.find('date')['to'] = date_cr1[0][-4:]\r\n",
        "    else: # Если том создавался один год (5 и 6 тома)\r\n",
        "        date_when = re.findall(r'\\d{4}', search)[0]\r\n",
        "        creation.find('date')['when'] = date_when\r\n",
        "        date_cr.string = date_when\r\n",
        "\r\n",
        "    # Информация об издании\r\n",
        "    edstmt = abz[0].text.split('//')\r\n",
        "    edstmt1 = edstmt[1].split('\\n')[0]\r\n",
        "    edition_stmt = soup_tei.find('editionstmt').find('p')\r\n",
        "    edition_stmt.string = edstmt1\r\n",
        "\r\n",
        "    # Номер тома\r\n",
        "    volume = re.findall(r'Т. \\d+.', edition_stmt.string)\r\n",
        "    volume_n = re.findall(r'\\d+', volume[0])\r\n",
        "    bibl_sc = soup_tei.find('biblscope')\r\n",
        "    bibl_sc.string = 'Том ' + volume_n[0]\r\n",
        "\r\n",
        "    # Получаем id нашего текста\r\n",
        "    get_ids = []\r\n",
        "    for link in soup_html.find_all('a'):\r\n",
        "        get_ids.append(link.get('href'))\r\n",
        "    text_id = get_ids[1].split('#')[1]\r\n",
        "\r\n",
        "    # Находим примечания к тексту на странице с примечаниями\r\n",
        "    first_tag = soup_notes_html.find('h4', attrs={'id':text_id})\r\n",
        "    next_tag = first_tag.find_next('h4')\r\n",
        "    all_tags = first_tag.find_all_next()\r\n",
        "\r\n",
        "    # Выбираем текст, в котором будем искать именованные сущности (текст произведения + сноски)\r\n",
        "    p = soup_html.find_all('p')\r\n",
        "    text1 = ''\r\n",
        "    for i in p:\r\n",
        "        if i.has_attr('class'):\r\n",
        "            text1 += i.text.split('\\n')[0]\r\n",
        "    for i in all_tags:\r\n",
        "        if i != next_tag: \r\n",
        "            if i.has_attr('class') and re.match(r'small\\S*', i['class'][0]) is not None:\r\n",
        "                text1 += i.text.split('\\n')[0]\r\n",
        "        else:\r\n",
        "            break\r\n",
        "\r\n",
        "    # Ищем имена\r\n",
        "    from natasha import (\r\n",
        "        Segmenter,\r\n",
        "        MorphVocab,\r\n",
        "    \r\n",
        "        NewsEmbedding,\r\n",
        "        NewsMorphTagger,\r\n",
        "        NewsSyntaxParser,\r\n",
        "        NewsNERTagger,\r\n",
        "    \r\n",
        "        PER,\r\n",
        "        NamesExtractor,\r\n",
        "        DatesExtractor,\r\n",
        "        MoneyExtractor,\r\n",
        "        AddrExtractor,\r\n",
        "\r\n",
        "        Doc\r\n",
        "    )\r\n",
        "\r\n",
        "    segmenter = Segmenter()\r\n",
        "    morph_vocab = MorphVocab()\r\n",
        "\r\n",
        "    emb = NewsEmbedding()\r\n",
        "    morph_tagger = NewsMorphTagger(emb)\r\n",
        "    syntax_parser = NewsSyntaxParser(emb)\r\n",
        "    ner_tagger = NewsNERTagger(emb)\r\n",
        "\r\n",
        "    names_extractor = NamesExtractor(morph_vocab)\r\n",
        "    dates_extractor = DatesExtractor(morph_vocab)\r\n",
        "    money_extractor = MoneyExtractor(morph_vocab)\r\n",
        "    addr_extractor = AddrExtractor(morph_vocab)\r\n",
        "\r\n",
        "    doc = Doc(text1)\r\n",
        "    doc.segment(segmenter)\r\n",
        "    doc.tag_morph(morph_tagger)\r\n",
        "    doc.parse_syntax(syntax_parser)\r\n",
        "    doc.tag_ner(ner_tagger)\r\n",
        "    #names = []\r\n",
        "    for span in doc.spans:\r\n",
        "        span.normalize(morph_vocab)\r\n",
        "    for span in doc.spans:\r\n",
        "        if span.type == PER:\r\n",
        "            span.extract_fact(names_extractor)\r\n",
        "            names = [[_.text, _.fact.as_dict] for _ in doc.spans if _.fact]\r\n",
        "\r\n",
        "    def delete_repeated(lst_names):\r\n",
        "        res_names = []\r\n",
        "        res_meta = []\r\n",
        "        for name in lst_names:\r\n",
        "            if name[0] not in res_names:\r\n",
        "                res_names.append(name[0])\r\n",
        "                res_meta.append(name[1])\r\n",
        "        return list(zip(list(res_names), res_meta))\r\n",
        "\r\n",
        "    def delete_postfixes(lst_names):\r\n",
        "        names = set(map(lambda x: x[0], lst_names))\r\n",
        "        for i in range(0, len(lst_names)-1):\r\n",
        "            for j in range(i+1, len(lst_names)):\r\n",
        "                if lst_names[i][0].startswith(lst_names[j][0]):\r\n",
        "                    names.remove(lst_names[i][0])\r\n",
        "                elif lst_names[j][0].startswith(lst_names[i][0]):\r\n",
        "                    names.remove(lst_names[j][0])\r\n",
        "        res = []\r\n",
        "        for name in lst_names:\r\n",
        "            if name[0] in names:\r\n",
        "                res.append(name)\r\n",
        "        return res\r\n",
        "\r\n",
        "    names = delete_repeated(names)\r\n",
        "    names = delete_postfixes(names)\r\n",
        "\r\n",
        "    # Ищем текст произведения\r\n",
        "    pars = soup_html.find_all(['p','span', 'img'])\r\n",
        "    body = soup_tei.select('text body')[0]\r\n",
        "    first_page = soup_html.find('span', class_='page').get('id')[2:]\r\n",
        "    pb_tag = soup_tei.new_tag('pb', attrs={'n':first_page})\r\n",
        "\r\n",
        "    # Получаем текст сносок\r\n",
        "    text = soup_html.find_all('a')[1:]\r\n",
        "    snos_list=[]\r\n",
        "    for i in range(len(text)):\r\n",
        "        a = text[i]\r\n",
        "        if a.has_attr('class') and a['class'][0] == 'footnote':\r\n",
        "            snos_list.append(a.text)\r\n",
        "        elif a.has_attr('href') and re.match(r'#$\\S*', a['href'][0]) is None:\r\n",
        "            snos_list.append(a.text)\r\n",
        "    snos_list = list(set(snos_list))\r\n",
        "\r\n",
        "    # Переносим текст, примечания и имена\r\n",
        "    for i in range(1,len(pars)):\r\n",
        "        cur_tag = pars[i]\r\n",
        "\r\n",
        "        if cur_tag.has_attr('class') and cur_tag['class'][0] == 'page': # Если это страница\r\n",
        "            cur_page = cur_tag.get('id')[2:]\r\n",
        "            pb_tag = soup_tei.new_tag('pb', attrs={'n':cur_page})\r\n",
        "            pb_tag.string = cur_tag.get('id')[2:]\r\n",
        "            body.append(pb_tag)\r\n",
        "\r\n",
        "        elif cur_tag.has_attr('alt'): # Если это изображение\r\n",
        "            fig_tag = soup_tei.new_tag('figure')\r\n",
        "            pb_tag.append(fig_tag)\r\n",
        "            graph_tag = soup_tei.new_tag('graphic')\r\n",
        "            fig_tag.append(graph_tag)\r\n",
        "            get_href = cur_tag.get('src').split('/')\r\n",
        "            fig_tag.find('graphic')['url'] = 'http://feb-web.ru/feb/chekhov/' + get_href[-2] + '/' + get_href[-1]\r\n",
        "            desc_tag = soup_tei.new_tag('figDesc')\r\n",
        "            fig_tag.append(desc_tag)\r\n",
        "            desc_tag.string = cur_tag.get('alt')\r\n",
        "            if cur_tag.find('a') is not None: # Если подпись изображения содержит примечание\r\n",
        "                for i in range(len(snos_list)):\r\n",
        "                    note_next_el = desc_tag.string[desc_tag.string.find(snos_list[i][-1])+1]\r\n",
        "                    note_prev_el = desc_tag.string[desc_tag.string.find(snos_list[i][0])-1]\r\n",
        "                    if note_prev_el != ' ':\r\n",
        "                        if note_next_el == ' ' or note_next_el == '.' or note_next_el == ',' or note_next_el == '!' or note_next_el == ':' or note_next_el == ';' or note_next_el == '?' or note_next_el == ')':\r\n",
        "                            desc_tag.string = desc_tag.string.replace(snos_list[i], '<note>'+snos_list[i]+'</note>')\r\n",
        "                    elif snos_list[i][0] != '1' and snos_list[i][0] != '2' and snos_list[i][0] != '3' and snos_list[i][0] != '4' and snos_list[i][0] != '5' and snos_list[i][0] != '6' and snos_list[i][0] != '7' and snos_list[i][0] != '8' and snos_list[i][0] != '9':\r\n",
        "                        desc_tag.string = desc_tag.string.replace(snos_list[i], '<note>'+snos_list[i]+'</note>')\r\n",
        "\r\n",
        "            for i in range(len(names)): # Если в подписи изображения есть имена\r\n",
        "                if names[i][0] in desc_tag.string:\r\n",
        "                    desc_tag.string = desc_tag.string.replace(names[i], '<PersName type=\"figure\">'+names[i]+'</PersName>')\r\n",
        "                    #desc_tag.string = re.sub(names[i][0][:-1] + r'(\\w*)', '<PersName type=\"figure\">'+names[i][0][:-1] + r'\\g<1>' +'</PersName>', desc_tag.string)\r\n",
        "                    if names[i][1].get('first') is not None:\r\n",
        "                        if len(names[i][1].get('first')) == 1:\r\n",
        "                            desc_tag.string = re.sub(names[i][1].get('first') + '.', '<forename xml:id=\"' + names[i][1].get('first') + '\">'+ names[i][1].get('first') + '.' +'</forename>', desc_tag.string)\r\n",
        "                        else:\r\n",
        "                            desc_tag.string = re.sub(names[i][1].get('first')[:-1] + r'(\\w*)', '<forename xml:id=\"' + names[i][1].get('first') + '\">'+ names[i][1].get('first')[:-1] + r'\\g<1>' +'</forename>', desc_tag.string)\r\n",
        "                    if names[i][1].get('last') is not None:\r\n",
        "                        if len(names[i][1].get('last')) == 1:\r\n",
        "                            desc_tag.string = re.sub(names[i][1].get('last') + '.', '<surname xml:id=\"' + names[i][1].get('last') + '\">'+ names[i][1].get('last') + '.' +'</surname>', desc_tag.string)\r\n",
        "                        else:\r\n",
        "                            desc_tag.string = re.sub(names[i][1].get('last')[:-1] + r'(\\w*)', '<surname xml:id=\"' + names[i][1].get('last') + '\">'+ names[i][1].get('last')[:-1] + r'\\g<1>' +'</surname>', desc_tag.string)\r\n",
        "                    if names[i][1].get('middle') is not None:\r\n",
        "                        if len(names[i][1].get('middle')) == 1:\r\n",
        "                            desc_tag.string = re.sub(names[i][1].get('middle') + '.', '<forename type=\"patronym\" xml:id=\"' + names[i][1].get('middle') + '\">'+ names[i][1].get('middle') + '.' +'</forename>', desc_tag.string)\r\n",
        "                        else:\r\n",
        "                            desc_tag.string = re.sub(names[i][1].get('middle')[:-1] + r'(\\w*)', '<forename type=\"patronym\" xml:id=\"' + names[i][1].get('middle') + '\">'+ names[i][1].get('middle')[:-1] + r'\\g<1>' +'</forename>', desc_tag.string)\r\n",
        "                \r\n",
        "            dates = list(dates_extractor(desc_tag.string)) # Если в подписи изображения есть даты\r\n",
        "            if len(dates) > 0:\r\n",
        "                for i in range(len(dates)-1, -1, -1):\r\n",
        "                    result = re.findall(r'\\d+', str(dates[i]))\r\n",
        "                    if len(result) == 3:\r\n",
        "                        desc_tag.string = desc_tag.string.replace(desc_tag.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '\">' + desc_tag.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "                    elif len(result) == 4:\r\n",
        "                        desc_tag.string = desc_tag.string.replace(desc_tag.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '-' + result[3] + '\">' + desc_tag.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "                    elif len(result) == 5:\r\n",
        "                        desc_tag.string = desc_tag.string.replace(desc_tag.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '-' + result[3] + '-' + result[4] + '\">' + desc_tag.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "\r\n",
        "        elif cur_tag.has_attr('class') and re.match(r'zg\\S*', cur_tag['class'][0]) is not None: # Если это подзаголовок\r\n",
        "            new_p = soup_tei.new_tag('p')\r\n",
        "            pb_tag.append(new_p)\r\n",
        "            tag_headline = soup_tei.new_tag('head')\r\n",
        "            new_p.append(tag_headline)\r\n",
        "            body.find('head')['rend'] = 'center'\r\n",
        "            body.find('head')['type'] = 'subtitle'\r\n",
        "            tag_headline.string = cur_tag.text.split('\\n')[0]\r\n",
        "            if cur_tag.find('a') is not None: # Если подзаголовок содержит примечание\r\n",
        "                for i in range(len(snos_list)):\r\n",
        "                    if snos_list[i] in tag_headline.string:\r\n",
        "                        tag_headline.string = tag_headline.string.replace(snos_list[i], '<note>'+snos_list[i]+'</note>')\r\n",
        "\r\n",
        "            for i in range(len(names)): # Если в подзаголовке есть имена\r\n",
        "                if names[i][0] in tag_headline.string:\r\n",
        "                    tag_headline.string = tag_headline.string.replace(i, '<PersName type=\"subtitle\">'+i+'</PersName>')\r\n",
        "                    #tag_headline.string = re.sub(names[i][0][:-1] + r'(\\w*)', '<PersName type=\"subtitle\">'+names[i][0][:-1] + r'\\g<1>' +'</PersName>', tag_headline.string)\r\n",
        "                    if names[i][1].get('first') is not None:\r\n",
        "                        if len(names[i][1].get('first')) == 1:\r\n",
        "                            tag_headline.string = re.sub(names[i][1].get('first') + '.', '<forename xml:id=\"' + names[i][1].get('first') + '\">'+ names[i][1].get('first') + '.' +'</forename>', tag_headline.string)\r\n",
        "                        else:\r\n",
        "                            tag_headline.string = re.sub(names[i][1].get('first')[:-1] + r'(\\w*)', '<forename xml:id=\"' + names[i][1].get('first') + '\">'+ names[i][1].get('first')[:-1] + r'\\g<1>' +'</forename>', tag_headline.string)\r\n",
        "                    if names[i][1].get('last') is not None:\r\n",
        "                        if len(names[i][1].get('last')) == 1:\r\n",
        "                            tag_headline.string = re.sub(names[i][1].get('last') + '.', '<surname xml:id=\"' + names[i][1].get('last') + '\">'+ names[i][1].get('last') + '.' +'</surname>', tag_headline.string)\r\n",
        "                        else:\r\n",
        "                            tag_headline.string = re.sub(names[i][1].get('last')[:-1] + r'(\\w*)', '<surname xml:id=\"' + names[i][1].get('last') + '\">'+ names[i][1].get('last')[:-1] + r'\\g<1>' +'</surname>', tag_headline.string)\r\n",
        "                    if names[i][1].get('middle') is not None:\r\n",
        "                        if len(names[i][1].get('middle')) == 1:\r\n",
        "                            tag_headline.string = re.sub(names[i][1].get('middle') + '.', '<forename type=\"patronym\" xml:id=\"' + names[i][1].get('middle') + '\">'+ names[i][1].get('middle') + '.' +'</forename>', tag_headline.string)\r\n",
        "                        else:\r\n",
        "                            tag_headline.string = re.sub(names[i][1].get('middle')[:-1] + r'(\\w*)', '<forename type=\"patronym\" xml:id=\"' + names[i][1].get('middle') + '\">'+ names[i][1].get('middle')[:-1] + r'\\g<1>' +'</forename>', tag_headline.string)\r\n",
        "\r\n",
        "            dates = list(dates_extractor(tag_headline.string)) # Если в подзаголовке есть даты\r\n",
        "            if len(dates) > 0:\r\n",
        "                for i in range(len(dates)-1, -1, -1):\r\n",
        "                    result = re.findall(r'\\d+', str(dates[i]))\r\n",
        "                    if len(result) == 3:\r\n",
        "                        tag_headline.string = tag_headline.string.replace(tag_headline.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '\">' + tag_headline.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "                    elif len(result) == 4:\r\n",
        "                        tag_headline.string = tag_headline.string.replace(tag_headline.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '-' + result[3] + '\">' + tag_headline.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "                    elif len(result) == 5:\r\n",
        "                        tag_headline.string = tag_headline.string.replace(tag_headline.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '-' + result[3] + '-' + result[4] + '\">' + tag_headline.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "\r\n",
        "        elif cur_tag.has_attr('class') and re.match(r'tit\\S*|zag\\S*', cur_tag['class'][0]) is not None: # Если это заголовок\r\n",
        "            new_p = soup_tei.new_tag('p')\r\n",
        "            pb_tag.append(new_p)\r\n",
        "            tag_headline = soup_tei.new_tag('head')\r\n",
        "            new_p.append(tag_headline)\r\n",
        "            body.find('head')['rend'] = 'center'\r\n",
        "            tag_hi = soup_tei.new_tag('hi') \r\n",
        "            tag_headline.append(tag_hi)\r\n",
        "            body.find('hi')['rend'] = 'strong'\r\n",
        "            tag_hi.string = cur_tag.text.split('\\n')[0]\r\n",
        "            if cur_tag.find('a') is not None: # Если заголовок содержит примечание\r\n",
        "                for i in range(len(snos_list)):\r\n",
        "                    if snos_list[i] in tag_hi.string:\r\n",
        "                        tag_hi.string = tag_hi.string.replace(snos_list[i], '<note>'+snos_list[i]+'</note>')\r\n",
        "        \r\n",
        "            for i in range(len(names)): # Если в заголовке есть имена\r\n",
        "                if names[i][0] in tag_hi.string:\r\n",
        "                    tag_hi.string = tag_hi.string.replace(i, '<PersName type=\"title\">'+i+'</PersName>')\r\n",
        "                    #tag_hi.string = re.sub(names[i][0][:-1] + r'(\\w*)', '<PersName type=\"title\">'+names[i][0][:-1] + r'\\g<1>' +'</PersName>', tag_hi.string)\r\n",
        "                    if names[i][1].get('first') is not None:\r\n",
        "                        if len(names[i][1].get('first')) == 1:\r\n",
        "                            tag_hi.string = re.sub(names[i][1].get('first') + '.', '<forename xml:id=\"' + names[i][1].get('first') + '\">'+ names[i][1].get('first') + '.' +'</forename>', tag_hi.string)\r\n",
        "                        else:\r\n",
        "                            tag_hi.string = re.sub(names[i][1].get('first')[:-1] + r'(\\w*)', '<forename xml:id=\"' + names[i][1].get('first') + '\">'+ names[i][1].get('first')[:-1] + r'\\g<1>' +'</forename>', tag_hi.string)\r\n",
        "                    if names[i][1].get('last') is not None:\r\n",
        "                        if len(names[i][1].get('last')) == 1:\r\n",
        "                            tag_hi.string = re.sub(names[i][1].get('last') + '.', '<surname xml:id=\"' + names[i][1].get('last') + '\">'+ names[i][1].get('last') + '.' +'</surname>', tag_hi.string)\r\n",
        "                        else:\r\n",
        "                            tag_hi.string = re.sub(names[i][1].get('last')[:-1] + r'(\\w*)', '<surname xml:id=\"' + names[i][1].get('last') + '\">'+ names[i][1].get('last')[:-1] + r'\\g<1>' +'</surname>', tag_hi.string)\r\n",
        "                    if names[i][1].get('middle') is not None:\r\n",
        "                        if len(names[i][1].get('middle')) == 1:\r\n",
        "                            tag_hi.string = re.sub(names[i][1].get('middle') + '.', '<forename type=\"patronym\" xml:id=\"' + names[i][1].get('middle') + '\">'+ names[i][1].get('middle') + '.' +'</forename>', tag_hi.string)\r\n",
        "                        else:\r\n",
        "                            tag_hi.string = re.sub(names[i][1].get('middle')[:-1] + r'(\\w*)', '<forename type=\"patronym\" xml:id=\"' + names[i][1].get('middle') + '\">'+ names[i][1].get('middle')[:-1] + r'\\g<1>' +'</forename>', tag_hi.string)\r\n",
        "        \r\n",
        "            dates = list(dates_extractor(tag_hi.string)) # Если в заголовке есть даты\r\n",
        "            if len(dates) > 0:\r\n",
        "                for i in range(len(dates)-1, -1, -1):\r\n",
        "                    result = re.findall(r'\\d+', str(dates[i]))\r\n",
        "                    if len(result) == 3:\r\n",
        "                        tag_hi.string = tag_hi.string.replace(tag_hi.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '\">' + tag_hi.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "                    elif len(result) == 4:\r\n",
        "                        tag_hi.string = tag_hi.string.replace(tag_hi.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '-' + result[3] + '\">' + tag_hi.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "                    elif len(result) == 5:\r\n",
        "                        tag_hi.string = tag_hi.string.replace(tag_hi.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '-' + result[3] + '-' + result[4] + '\">' + tag_hi.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "\r\n",
        "        elif cur_tag.has_attr('class') and re.match(r'epig\\S*', cur_tag['class'][0]) is not None: # Если это эпиграф\r\n",
        "            new_p = soup_tei.new_tag('p')\r\n",
        "            pb_tag.append(new_p)\r\n",
        "            tag_epigraph = soup_tei.new_tag('epigraph')\r\n",
        "            new_p.append(tag_epigraph)\r\n",
        "            body.find('epigraph')['rend'] = 'right'\r\n",
        "            tag_epigraph.string = cur_tag.text\r\n",
        "            if cur_tag.find('a') is not None: # Если эпиграф содержит примечание\r\n",
        "                for i in range(len(snos_list)):\r\n",
        "                    note_next_el = tag_epigraph.string[tag_epigraph.string.find(snos_list[i][-1])+1]\r\n",
        "                    note_prev_el = tag_epigraph.string[tag_epigraph.string.find(snos_list[i][0])-1]\r\n",
        "                    if note_prev_el != ' ':\r\n",
        "                        if note_next_el == ' ' or note_next_el == '.' or note_next_el == ',' or note_next_el == '!' or note_next_el == ':' or note_next_el == ';' or note_next_el == '?' or note_next_el == ')':\r\n",
        "                            tag_epigraph.string = tag_epigraph.string.replace(snos_list[i], '<note>'+snos_list[i]+'</note>')\r\n",
        "                    elif snos_list[i][0] != '1' and snos_list[i][0] != '2' and snos_list[i][0] != '3' and snos_list[i][0] != '4' and snos_list[i][0] != '5' and snos_list[i][0] != '6' and snos_list[i][0] != '7' and snos_list[i][0] != '8' and snos_list[i][0] != '9':\r\n",
        "                        tag_epigraph.string = tag_epigraph.string.replace(snos_list[i], '<note>'+snos_list[i]+'</note>')\r\n",
        "        \r\n",
        "            for i in range(len(names)): # Если в эпиграфе есть имена\r\n",
        "                if names[i][0] in tag_epigraph.string:\r\n",
        "                    tag_epigraph.string = tag_epigraph.string.replace(names[i][0], '<PersName type=\"epigraph\">'+names[i][0]+'</PersName>')\r\n",
        "                    #tag_epigraph.string = re.sub(names[i][0][:-1] + r'(\\w*)', '<PersName type=\"epigraph\">'+names[i][0][:-1] + r'\\g<1>' +'</PersName>', tag_epigraph.string)\r\n",
        "                    if names[i][1].get('first') is not None:\r\n",
        "                        if len(names[i][1].get('first')) == 1:\r\n",
        "                            tag_epigraph.string = re.sub(names[i][1].get('first') + '.', '<forename xml:id=\"' + names[i][1].get('first') + '\">'+ names[i][1].get('first') + '.' +'</forename>', tag_epigraph.string)\r\n",
        "                        else:\r\n",
        "                            tag_epigraph.string = re.sub(names[i][1].get('first')[:-1] + r'(\\w*)', '<forename xml:id=\"' + names[i][1].get('first') + '\">'+ names[i][1].get('first')[:-1] + r'\\g<1>' +'</forename>', tag_epigraph.string)\r\n",
        "                    if names[i][1].get('last') is not None:\r\n",
        "                        if len(names[i][1].get('last')) == 1:\r\n",
        "                            tag_epigraph.string = re.sub(names[i][1].get('last') + '.', '<surname xml:id=\"' + names[i][1].get('last') + '\">'+ names[i][1].get('last') + '.' +'</surname>', tag_epigraph.string)\r\n",
        "                        else:\r\n",
        "                            tag_epigraph.string = re.sub(names[i][1].get('last')[:-1] + r'(\\w*)', '<surname xml:id=\"' + names[i][1].get('last') + '\">'+ names[i][1].get('last')[:-1] + r'\\g<1>' +'</surname>', tag_epigraph.string)\r\n",
        "                    if names[i][1].get('middle') is not None:\r\n",
        "                        if len(names[i][1].get('middle')) == 1:\r\n",
        "                            tag_epigraph.string = re.sub(names[i][1].get('middle') + '.', '<forename type=\"patronym\" xml:id=\"' + names[i][1].get('middle') + '\">'+ names[i][1].get('middle') + '.' +'</forename>', tag_epigraph.string)\r\n",
        "                        else:\r\n",
        "                            tag_epigraph.string = re.sub(names[i][1].get('middle')[:-1] + r'(\\w*)', '<forename type=\"patronym\" xml:id=\"' + names[i][1].get('middle') + '\">'+ names[i][1].get('middle')[:-1] + r'\\g<1>' +'</forename>', tag_epigraph.string)\r\n",
        "        \r\n",
        "            dates = list(dates_extractor(tag_epigraph.string)) # Если в эпиграфе есть даты\r\n",
        "            if len(dates) > 0:\r\n",
        "                for i in range(len(dates)-1, -1, -1):\r\n",
        "                    result = re.findall(r'\\d+', str(dates[i]))\r\n",
        "                    if len(result) == 3:\r\n",
        "                        tag_epigraph.string = tag_epigraph.string.replace(tag_epigraph.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '\">' + tag_epigraph.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "                    elif len(result) == 4:\r\n",
        "                        tag_epigraph.string = tag_epigraph.string.replace(tag_epigraph.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '-' + result[3] + '\">' + tag_epigraph.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "                    elif len(result) == 5:\r\n",
        "                        tag_epigraph.string = tag_epigraph.string.replace(tag_epigraph.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '-' + result[3] + '-' + result[4] + '\">' + tag_epigraph.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "\r\n",
        "        elif cur_tag.has_attr('class') and re.match(r'obraw\\S*', cur_tag['class'][0]) is not None: # Если это приветствие/обращение (в письме)\r\n",
        "            new_p = soup_tei.new_tag('p')\r\n",
        "            pb_tag.append(new_p)\r\n",
        "            tag_salute = soup_tei.new_tag('salute')\r\n",
        "            new_p.append(tag_salute)\r\n",
        "            tag_salute.string = cur_tag.text.split('\\n')[0]\r\n",
        "            if cur_tag.find('a') is not None: # Если обращение содержит примечание\r\n",
        "                for i in range(len(snos_list)):\r\n",
        "                    note_next_el = tag_salute.string[tag_salute.string.find(snos_list[i][-1])+1]\r\n",
        "                    note_prev_el = tag_salute.string[tag_salute.string.find(snos_list[i][0])-1]\r\n",
        "                    if note_prev_el != ' ':\r\n",
        "                        if note_next_el == ' ' or note_next_el == '.' or note_next_el == ',' or note_next_el == '!' or note_next_el == ':' or note_next_el == ';' or note_next_el == '?' or note_next_el == ')':\r\n",
        "                            tag_salute.string = tag_salute.string.replace(snos_list[i], '<note>'+snos_list[i]+'</note>')\r\n",
        "                    elif snos_list[i][0] != '1' and snos_list[i][0] != '2' and snos_list[i][0] != '3' and snos_list[i][0] != '4' and snos_list[i][0] != '5' and snos_list[i][0] != '6' and snos_list[i][0] != '7' and snos_list[i][0] != '8' and snos_list[i][0] != '9':\r\n",
        "                        tag_salute.string = tag_salute.string.replace(snos_list[i], '<note>'+snos_list[i]+'</note>')\r\n",
        "        \r\n",
        "            for i in range(len(names)): # Если в обращении есть имена\r\n",
        "                if names[i][0] in tag_salute.string:\r\n",
        "                    tag_salute.string = tag_salute.string.replace(names[i][0], '<PersName type=\"salute\">'+names[i][0]+'</PersName>')\r\n",
        "                    #tag_salute.string = re.sub(names[i][0][:-1] + r'(\\w*)', '<PersName type=\"salute\">'+names[i][0][:-1] + r'\\g<1>' +'</PersName>', tag_salute.string)\r\n",
        "                    if names[i][1].get('first') is not None:\r\n",
        "                        if len(names[i][1].get('first')) == 1:\r\n",
        "                            tag_salute.string = re.sub(names[i][1].get('first') + '.', '<forename xml:id=\"' + names[i][1].get('first') + '\">'+ names[i][1].get('first') + '.' +'</forename>', tag_salute.string)\r\n",
        "                        else:\r\n",
        "                            tag_salute.string = re.sub(names[i][1].get('first')[:-1] + r'(\\w*)', '<forename xml:id=\"' + names[i][1].get('first') + '\">'+ names[i][1].get('first')[:-1] + r'\\g<1>' +'</forename>', tag_salute.string)\r\n",
        "                    if names[i][1].get('last') is not None:\r\n",
        "                        if len(names[i][1].get('last')) == 1:\r\n",
        "                            tag_salute.string = re.sub(names[i][1].get('last') + '.', '<surname xml:id=\"' + names[i][1].get('last') + '\">'+ names[i][1].get('last') + '.' +'</surname>', tag_salute.string)\r\n",
        "                        else:\r\n",
        "                            tag_salute.string = re.sub(names[i][1].get('last')[:-1] + r'(\\w*)', '<surname xml:id=\"' + names[i][1].get('last') + '\">'+ names[i][1].get('last')[:-1] + r'\\g<1>' +'</surname>', tag_salute.string)\r\n",
        "                    if names[i][1].get('middle') is not None:\r\n",
        "                        if len(names[i][1].get('middle')) == 1:\r\n",
        "                            tag_salute.string = re.sub(names[i][1].get('middle') + '.', '<forename type=\"patronym\" xml:id=\"' + names[i][1].get('middle') + '\">'+ names[i][1].get('middle') + '.' +'</forename>', tag_salute.string)\r\n",
        "                        else:\r\n",
        "                            tag_salute.string = re.sub(names[i][1].get('middle')[:-1] + r'(\\w*)', '<forename type=\"patronym\" xml:id=\"' + names[i][1].get('middle') + '\">'+ names[i][1].get('middle')[:-1] + r'\\g<1>' +'</forename>', tag_salute.string)\r\n",
        "        \r\n",
        "            dates = list(dates_extractor(tag_salute.string)) # Если в обращении есть даты\r\n",
        "            if len(dates) > 0:\r\n",
        "                for i in range(len(dates)-1, -1, -1):\r\n",
        "                    result = re.findall(r'\\d+', str(dates[i]))\r\n",
        "                    if len(result) == 3:\r\n",
        "                        tag_salute.string = tag_salute.string.replace(tag_salute.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '\">' + tag_salute.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "                    elif len(result) == 4:\r\n",
        "                        tag_salute.string = tag_salute.string.replace(tag_salute.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '-' + result[3] + '\">' + tag_salute.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "                    elif len(result) == 5:\r\n",
        "                        tag_salute.string = tag_salute.string.replace(tag_salute.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '-' + result[3] + '-' + result[4] + '\">' + tag_salute.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "\r\n",
        "        elif cur_tag.has_attr('class') and re.match(r'podp\\S*', cur_tag['class'][0]) is not None: # Если это подпись (в письме)\r\n",
        "            new_p = soup_tei.new_tag('p')\r\n",
        "            pb_tag.append(new_p)\r\n",
        "            tag_podp = soup_tei.new_tag('signed')\r\n",
        "            new_p.append(tag_podp)\r\n",
        "            tag_podp.string = cur_tag.text.split('\\n')[0]\r\n",
        "            if cur_tag.find('a') is not None: # Если подпись содержит примечание\r\n",
        "                for i in range(len(snos_list)):\r\n",
        "                    note_next_el = tag_podp.string[tag_podp.string.find(snos_list[i][-1])+1]\r\n",
        "                    note_prev_el = tag_podp.string[tag_podp.string.find(snos_list[i][0])-1]\r\n",
        "                    if note_prev_el != ' ':\r\n",
        "                        if note_next_el == ' ' or note_next_el == '.' or note_next_el == ',' or note_next_el == '!' or note_next_el == ':' or note_next_el == ';' or note_next_el == '?' or note_next_el == ')':\r\n",
        "                            tag_podp.string = tag_podp.string.replace(snos_list[i], '<note>'+snos_list[i]+'</note>')\r\n",
        "                    elif snos_list[i][0] != '1' and snos_list[i][0] != '2' and snos_list[i][0] != '3' and snos_list[i][0] != '4' and snos_list[i][0] != '5' and snos_list[i][0] != '6' and snos_list[i][0] != '7' and snos_list[i][0] != '8' and snos_list[i][0] != '9':\r\n",
        "                        tag_podp.string = tag_podp.string.replace(snos_list[i], '<note>'+snos_list[i]+'</note>')\r\n",
        "        \r\n",
        "            for i in range(len(names)): # Если в подписи есть имена\r\n",
        "                if names[i][0] in tag_podp.string:\r\n",
        "                    tag_podp.string = tag_podp.string.replace(names[i][0], '<PersName type=\"signed\">'+names[i][0]+'</PersName>')\r\n",
        "                    #tag_podp.string = re.sub(names[i][0][:-1] + r'(\\w*)', '<PersName type=\"signed\">'+names[i][0][:-1] + r'\\g<1>' +'</PersName>', tag_podp.string)\r\n",
        "                    if names[i][1].get('first') is not None:\r\n",
        "                        if len(names[i][1].get('first')) == 1:\r\n",
        "                            tag_podp.string = re.sub(names[i][1].get('first') + '.', '<forename xml:id=\"' + names[i][1].get('first') + '\">'+ names[i][1].get('first') + '.' +'</forename>', tag_podp.string)\r\n",
        "                        else:\r\n",
        "                            tag_podp.string = re.sub(names[i][1].get('first')[:-1] + r'(\\w*)', '<forename xml:id=\"' + names[i][1].get('first') + '\">'+ names[i][1].get('first')[:-1] + r'\\g<1>' +'</forename>', tag_podp.string)\r\n",
        "                    if names[i][1].get('last') is not None:\r\n",
        "                        if len(names[i][1].get('last')) == 1:\r\n",
        "                            tag_podp.string = re.sub(names[i][1].get('last') + '.', '<surname xml:id=\"' + names[i][1].get('last') + '\">'+ names[i][1].get('last') + '.' +'</surname>', tag_podp.string)\r\n",
        "                        else:\r\n",
        "                            tag_podp.string = re.sub(names[i][1].get('last')[:-1] + r'(\\w*)', '<surname xml:id=\"' + names[i][1].get('last') + '\">'+ names[i][1].get('last')[:-1] + r'\\g<1>' +'</surname>', tag_podp.string)\r\n",
        "                    if names[i][1].get('middle') is not None:\r\n",
        "                        if len(names[i][1].get('middle')) == 1:\r\n",
        "                            tag_podp.string = re.sub(names[i][1].get('middle') + '.', '<forename type=\"patronym\" xml:id=\"' + names[i][1].get('middle') + '\">'+ names[i][1].get('middle') + '.' +'</forename>', tag_podp.string)\r\n",
        "                        else:\r\n",
        "                            tag_podp.string = re.sub(names[i][1].get('middle')[:-1] + r'(\\w*)', '<forename type=\"patronym\" xml:id=\"' + names[i][1].get('middle') + '\">'+ names[i][1].get('middle')[:-1] + r'\\g<1>' +'</forename>', tag_podp.string)\r\n",
        "        \r\n",
        "            dates = list(dates_extractor(tag_podp.string)) # Если в подписи есть даты\r\n",
        "            if len(dates) > 0:\r\n",
        "                for i in range(len(dates)-1, -1, -1):\r\n",
        "                    result = re.findall(r'\\d+', str(dates[i]))\r\n",
        "                    if len(result) == 3:\r\n",
        "                        tag_podp.string = tag_podp.string.replace(tag_podp.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '\">' + tag_podp.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "                    elif len(result) == 4:\r\n",
        "                        tag_podp.string = tag_podp.string.replace(tag_podp.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '-' + result[3] + '\">' + tag_podp.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "                    elif len(result) == 5:\r\n",
        "                        tag_podp.string = tag_podp.string.replace(tag_podp.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '-' + result[3] + '-' + result[4] + '\">' + tag_podp.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "\r\n",
        "        elif cur_tag.has_attr('class') and re.match(r'text\\S*|curs\\S*|small\\S*|vis\\S*|center\\S*', cur_tag['class'][0]) is not None: # Если это текст\r\n",
        "            new_p = soup_tei.new_tag('p')\r\n",
        "            pb_tag.append(new_p) \r\n",
        "            new_p.string = cur_tag.text.split('\\n')[0]\r\n",
        "            if cur_tag.find('a') is not None: # Размечаем сноски внутри текста\r\n",
        "                for i in range(len(snos_list)):\r\n",
        "                    note_next_el = new_p.string[new_p.string.find(snos_list[i][-1])+1]\r\n",
        "                    note_prev_el = new_p.string[new_p.string.find(snos_list[i][0])-1]\r\n",
        "                    if note_prev_el != ' ':\r\n",
        "                        if note_next_el == ' ' or note_next_el == '.' or note_next_el == ',' or note_next_el == '!' or note_next_el == ':' or note_next_el == ';' or note_next_el == '?' or note_next_el == ')':\r\n",
        "                            new_p.string = new_p.string.replace(snos_list[i], '<note>'+snos_list[i]+'</note>')\r\n",
        "                    elif snos_list[i][0] != '1' and snos_list[i][0] != '2' and snos_list[i][0] != '3' and snos_list[i][0] != '4' and snos_list[i][0] != '5' and snos_list[i][0] != '6' and snos_list[i][0] != '7' and snos_list[i][0] != '8' and snos_list[i][0] != '9':\r\n",
        "                        new_p.string = new_p.string.replace(snos_list[i], '<note>'+snos_list[i]+'</note>')\r\n",
        "        \r\n",
        "            for i in range(len(names)): # Если в тексте есть имена\r\n",
        "                if names[i][0] in new_p.string:\r\n",
        "                    new_p.string = new_p.string.replace(names[i][0], '<PersName type=\"text\">'+names[i][0]+'</PersName>')\r\n",
        "                    #new_p.string = re.sub(names[i][0][:-1] + r'(\\w*)', '<PersName type=\"text\">'+names[i][0][:-1] + r'\\g<1>' +'</PersName>', new_p.string)\r\n",
        "                    if names[i][1].get('first') is not None:\r\n",
        "                        if len(names[i][1].get('first')) == 1:\r\n",
        "                            new_p.string = re.sub(names[i][1].get('first') + '.', '<forename xml:id=\"' + names[i][1].get('first') + '\">'+ names[i][1].get('first') + '.' +'</forename>', new_p.string)\r\n",
        "                        else:\r\n",
        "                            new_p.string = re.sub(names[i][1].get('first')[:-1] + r'(\\w*)', '<forename xml:id=\"' + names[i][1].get('first') + '\">'+ names[i][1].get('first')[:-1] + r'\\g<1>' +'</forename>', new_p.string)\r\n",
        "                    if names[i][1].get('last') is not None:\r\n",
        "                        if len(names[i][1].get('last')) == 1:\r\n",
        "                            new_p.string = re.sub(names[i][1].get('last') + '.', '<surname xml:id=\"' + names[i][1].get('last') + '\">'+ names[i][1].get('last') + '.' +'</surname>', new_p.string)\r\n",
        "                        else:\r\n",
        "                            new_p.string = re.sub(names[i][1].get('last')[:-1] + r'(\\w*)', '<surname xml:id=\"' + names[i][1].get('last') + '\">'+ names[i][1].get('last')[:-1] + r'\\g<1>' +'</surname>', new_p.string)\r\n",
        "                    if names[i][1].get('middle') is not None:\r\n",
        "                        if len(names[i][1].get('middle')) == 1:\r\n",
        "                            new_p.string = re.sub(names[i][1].get('middle') + '.', '<forename type=\"patronym\" xml:id=\"' + names[i][1].get('middle') + '\">'+ names[i][1].get('middle') + '.' +'</forename>', new_p.string)\r\n",
        "                        else:\r\n",
        "                             new_p.string = re.sub(names[i][1].get('middle')[:-1] + r'(\\w*)', '<forename type=\"patronym\" xml:id=\"' + names[i][1].get('middle') + '\">'+ names[i][1].get('middle')[:-1] + r'\\g<1>' +'</forename>', new_p.string)\r\n",
        "        \r\n",
        "            dates = list(dates_extractor(new_p.string)) # Если в тексте есть даты\r\n",
        "            if len(dates) > 0:\r\n",
        "                for i in range(len(dates)-1, -1, -1):\r\n",
        "                    result = re.findall(r'\\d+', str(dates[i]))\r\n",
        "                    if len(result) == 3:\r\n",
        "                        new_p.string = new_p.string.replace(new_p.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '\">' + new_p.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "                    elif len(result) == 4:\r\n",
        "                        new_p.string = new_p.string.replace(new_p.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '-' + result[3] + '\">' + new_p.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "                    elif len(result) == 5:\r\n",
        "                        new_p.string = new_p.string.replace(new_p.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '-' + result[3] + '-' + result[4] + '\">' + new_p.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "\r\n",
        "    # Переносим сноски\r\n",
        "    link_tag = soup_tei.new_tag('linkGrp')\r\n",
        "    body.append(link_tag)\r\n",
        "    link_tag.string = 'Примечания'\r\n",
        "\r\n",
        "    note_tag = soup_tei.new_tag('link')\r\n",
        "    link_tag.append(note_tag)\r\n",
        "\r\n",
        "    for i in all_tags:\r\n",
        "        if i != next_tag: \r\n",
        "            if i.has_attr('class') and re.match(r'small\\S*|prim\\S*|text\\S*|txt\\S*|mtext\\S*', i['class'][0]) is not None:\r\n",
        "                if i.text[0:4] != 'Стр.':\r\n",
        "                    new_p = soup_tei.new_tag('p')\r\n",
        "                    note_tag.append(new_p)\r\n",
        "                    new_p.string = i.text.split('\\n')[0]\r\n",
        "                    for j in range(len(names)): # Если в примечании есть имена\r\n",
        "                        if names[j][0] in new_p.string:\r\n",
        "                            new_p.string = new_p.string.replace(names[j][0], '<PersName type=\"note\">'+names[j][0]+'</PersName>')\r\n",
        "                            #new_p.string = re.sub(names[j][0][:-1] + r'(\\w*)', '<PersName type=\"note\">'+names[j][0][:-1] + r'\\g<1>' +'</PersName>', new_p.string)\r\n",
        "                            if names[j][1].get('first') is not None:\r\n",
        "                                if len(names[j][1].get('first')) == 1:\r\n",
        "                                    new_p.string = re.sub(names[j][1].get('first') + '.', '<forename xml:id=\"' + names[j][1].get('first') + '\">'+ names[j][1].get('first') + '.' +'</forename>', new_p.string)\r\n",
        "                                else:\r\n",
        "                                    new_p.string = re.sub(names[j][1].get('first')[:-1] + r'(\\w*)', '<forename xml:id=\"' + names[j][1].get('first') + '\">'+ names[j][1].get('first')[:-1] + r'\\g<1>' +'</forename>', new_p.string)\r\n",
        "                            if names[j][1].get('last') is not None:\r\n",
        "                                if len(names[j][1].get('last')) == 1:\r\n",
        "                                    new_p.string = re.sub(names[j][1].get('last') + '.', '<surname xml:id=\"' + names[j][1].get('last') + '\">'+ names[j][1].get('last') + '.' +'</surname>', new_p.string)\r\n",
        "                                else:\r\n",
        "                                    new_p.string = re.sub(names[j][1].get('last')[:-1] + r'(\\w*)', '<surname xml:id=\"' + names[j][1].get('last') + '\">'+ names[j][1].get('last')[:-1] + r'\\g<1>' +'</surname>', new_p.string)\r\n",
        "                            if names[j][1].get('middle') is not None:\r\n",
        "                                if len(names[j][1].get('middle')) == 1:\r\n",
        "                                    new_p.string = re.sub(names[j][1].get('middle') + '.', '<forename type=\"patronym\" xml:id=\"' + names[j][1].get('middle') + '\">'+ names[j][1].get('middle') + '.' +'</forename>', new_p.string)\r\n",
        "                                else:\r\n",
        "                                    new_p.string = re.sub(names[j][1].get('middle')[:-1] + r'(\\w*)', '<forename type=\"patronym\" xml:id=\"' + names[j][1].get('middle') + '\">'+ names[j][1].get('middle')[:-1] + r'\\g<1>' +'</forename>', new_p.string)\r\n",
        "                \r\n",
        "                    dates = list(dates_extractor(new_p.string)) # Если в примечании есть даты\r\n",
        "                    if len(dates) > 0:\r\n",
        "                        for j in range(len(dates)-1, -1, -1):\r\n",
        "                            result = re.findall(r'\\d+', str(dates[j]))\r\n",
        "                            if len(result) == 3:\r\n",
        "                                new_p.string = new_p.string.replace(new_p.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '\">' + new_p.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "                            elif len(result) == 4:\r\n",
        "                                new_p.string = new_p.string.replace(new_p.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '-' + result[3] + '\">' + new_p.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "                            elif len(result) == 5:\r\n",
        "                                new_p.string = new_p.string.replace(new_p.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '-' + result[3] + '-' + result[4] + '\">' + new_p.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "            \r\n",
        "                elif i.text[0:4] == 'Стр.':\r\n",
        "                    note_tag1 = soup_tei.new_tag('link')\r\n",
        "                    link_tag.append(note_tag1)\r\n",
        "                    new_p = soup_tei.new_tag('p')\r\n",
        "                    note_tag1.append(new_p)\r\n",
        "                    new_p.string = i.text.split('\\n')[0]\r\n",
        "                \r\n",
        "                    for i in range(len(names)): # Если в примечании есть имена #2\r\n",
        "                        if names[i][0] in new_p.string:\r\n",
        "                            new_p.string = new_p.string.replace(names[i][0], '<PersName type=\"note\">'+names[i][0]+'</PersName>')\r\n",
        "                            #new_p.string = re.sub(names[i][0][:-1] + r'(\\w*)', '<PersName type=\"note\">'+names[i][0][:-1] + r'\\g<1>' +'</PersName>', new_p.string)\r\n",
        "                            if names[i][1].get('first') is not None:\r\n",
        "                                if len(names[i][1].get('first')) == 1:\r\n",
        "                                    new_p.string = re.sub(names[i][1].get('first') + '.', '<forename xml:id=\"' + names[i][1].get('first') + '\">'+ names[i][1].get('first') + '.' +'</forename>', new_p.string)\r\n",
        "                                else:\r\n",
        "                                    new_p.string = re.sub(names[i][1].get('first')[:-1] + r'(\\w*)', '<forename xml:id=\"' + names[i][1].get('first') + '\">'+ names[i][1].get('first')[:-1] + r'\\g<1>' +'</forename>', new_p.string)\r\n",
        "                            if names[i][1].get('last') is not None:\r\n",
        "                                if len(names[i][1].get('last')) == 1:\r\n",
        "                                    new_p.string = re.sub(names[i][1].get('last') + '.', '<surname xml:id=\"' + names[i][1].get('last') + '\">'+ names[i][1].get('last') + '.' +'</surname>', new_p.string)\r\n",
        "                                else:\r\n",
        "                                    new_p.string = re.sub(names[i][1].get('last')[:-1] + r'(\\w*)', '<surname xml:id=\"' + names[i][1].get('last') + '\">'+ names[i][1].get('last')[:-1] + r'\\g<1>' +'</surname>', new_p.string)\r\n",
        "                            if names[i][1].get('middle') is not None:\r\n",
        "                                if len(names[i][1].get('middle')) == 1:\r\n",
        "                                    new_p.string = re.sub(names[i][1].get('middle') + '.', '<forename type=\"patronym\" xml:id=\"' + names[i][1].get('middle') + '\">'+ names[i][1].get('middle') + '.' +'</forename>', new_p.string)\r\n",
        "                                else:\r\n",
        "                                    new_p.string = re.sub(names[i][1].get('middle')[:-1] + r'(\\w*)', '<forename type=\"patronym\" xml:id=\"' + names[i][1].get('middle') + '\">'+ names[i][1].get('middle')[:-1] + r'\\g<1>' +'</forename>', new_p.string)\r\n",
        "                \r\n",
        "                    dates = list(dates_extractor(new_p.string)) # Если в примечании есть даты\r\n",
        "                    if len(dates) > 0:\r\n",
        "                        for i in range(len(dates)-1, -1, -1):\r\n",
        "                            result = re.findall(r'\\d+', str(dates[i]))\r\n",
        "                            if len(result) == 3:\r\n",
        "                                new_p.string = new_p.string.replace(new_p.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '\">' + new_p.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "                            elif len(result) == 4:\r\n",
        "                                new_p.string = new_p.string.replace(new_p.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '-' + result[3] + '\">' + new_p.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "                            elif len(result) == 5:\r\n",
        "                                new_p.string = new_p.string.replace(new_p.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '-' + result[3] + '-' + result[4] + '\">' + new_p.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "            \r\n",
        "        else:\r\n",
        "            break\r\n",
        "\r\n",
        "    # Получаем примечания внутри произведения из раздела сноски\r\n",
        "    text = soup_html.find_all('p', class_='snos')\r\n",
        "    for i in range(len(text)):\r\n",
        "        a = text[i]\r\n",
        "        note_tag = soup_tei.new_tag('link')\r\n",
        "        link_tag.append(note_tag)\r\n",
        "        note_tag.string = a.text\r\n",
        "  \r\n",
        "        for i in range(len(names)): # Если в примечании есть имена #3\r\n",
        "            if names[i][0] in note_tag.string:\r\n",
        "                note_tag.string = note_tag.string.replace(names[i][0], '<PersName type=\"note\">'+names[i][0]+'</PersName>')\r\n",
        "                #note_tag.string = re.sub(names[i][0][:-1] + r'(\\w*)', '<PersName type=\"note\">'+names[i][0][:-1] + r'\\g<1>' +'</PersName>', note_tag.string)\r\n",
        "                if names[i][1].get('first') is not None:\r\n",
        "                    if len(names[i][1].get('first')) == 1:\r\n",
        "                        note_tag.string = re.sub(names[i][1].get('first') + '.', '<forename xml:id=\"' + names[i][1].get('first') + '\">'+ names[i][1].get('first') + '.' +'</forename>', note_tag.string)\r\n",
        "                    else:\r\n",
        "                        note_tag.string = re.sub(names[i][1].get('first')[:-1] + r'(\\w*)', '<forename xml:id=\"' + names[i][1].get('first') + '\">'+ names[i][1].get('first')[:-1] + r'\\g<1>' +'</forename>', note_tag.string)\r\n",
        "                if names[i][1].get('last') is not None:\r\n",
        "                    if len(names[i][1].get('last')) == 1:\r\n",
        "                        note_tag.string = re.sub(names[i][1].get('last') + '.', '<surname xml:id=\"' + names[i][1].get('last') + '\">'+ names[i][1].get('last') + '.' +'</surname>', note_tag.string)\r\n",
        "                    else:\r\n",
        "                        note_tag.string = re.sub(names[i][1].get('last')[:-1] + r'(\\w*)', '<surname xml:id=\"' + names[i][1].get('last') + '\">'+ names[i][1].get('last')[:-1] + r'\\g<1>' +'</surname>', note_tag.string)\r\n",
        "                if names[i][1].get('middle') is not None:\r\n",
        "                    if len(names[i][1].get('middle')) == 1:\r\n",
        "                        note_tag.string = re.sub(names[i][1].get('middle') + '.', '<forename type=\"patronym\" xml:id=\"' + names[i][1].get('middle') + '\">'+ names[i][1].get('middle') + '.' +'</forename>', note_tag.string)\r\n",
        "                    else:\r\n",
        "                        note_tag.string = re.sub(names[i][1].get('middle')[:-1] + r'(\\w*)', '<forename type=\"patronym\" xml:id=\"' + names[i][1].get('middle') + '\">'+ names[i][1].get('middle')[:-1] + r'\\g<1>' +'</forename>', note_tag.string)\r\n",
        "  \r\n",
        "        dates = list(dates_extractor(note_tag.string)) # Если в примечании есть даты\r\n",
        "        if len(dates) > 0:\r\n",
        "            for i in range(len(dates)-1, -1, -1):\r\n",
        "                result = re.findall(r'\\d+', str(dates[i]))\r\n",
        "                if len(result) == 3:\r\n",
        "                    note_tag.string = note_tag.string.replace(note_tag.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '\">' + note_tag.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "                elif len(result) == 4:\r\n",
        "                    note_tag.string = note_tag.string.replace(note_tag.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '-' + result[3] + '\">' + note_tag.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "                elif len(result) == 5:\r\n",
        "                    note_tag.string = note_tag.string.replace(note_tag.string[int(result[0]):int(result[1])], '<date when=\"' + result[2] + '-' + result[3] + '-' + result[4] + '\">' + note_tag.string[int(result[0]):int(result[1])] + '</date>')\r\n",
        "\r\n",
        "    tei_doc = str(soup_tei.prettify()[2:])\r\n",
        "    tei_doc = tei_doc.replace('&lt;', '<')\r\n",
        "    tei_doc = tei_doc.replace('&gt;', '>')\r\n",
        "\r\n",
        "    file = open('done.xml', 'w', encoding='utf8')\r\n",
        "    file.write(tei_doc)\r\n",
        "    file.close()\r\n",
        "\r\n",
        "    # Присваиваем примечаниям id\r\n",
        "    file_tei = open('done.xml','r',encoding='utf8')\r\n",
        "    content = file_tei.read()\r\n",
        "    file_tei.close()\r\n",
        "    soup_tei = BeautifulSoup(content, 'html.parser')\r\n",
        "\r\n",
        "    body = soup_tei.find('body')\r\n",
        "    notes = body.find_all('note')\r\n",
        "    count = 1\r\n",
        "    for i in range(len(notes)):\r\n",
        "        if re.match(r'\\d+', notes[i].text) is not None:\r\n",
        "            notes[i]['xml:id'] = 'note'+str(count)\r\n",
        "            count += 1\r\n",
        "\r\n",
        "    link_gr = soup_tei.find('linkgrp')\r\n",
        "    links = link_gr.find_all('link')[-len(notes)+1:]\r\n",
        "    cnt = 1\r\n",
        "    for i in range(len(links)):\r\n",
        "        if re.match(r'\\d+', links[i].text) is not None:\r\n",
        "            links[i]['target'] = '#note'+str(cnt)\r\n",
        "            cnt += 1\r\n",
        "\r\n",
        "    for i in range(len(notes)):\r\n",
        "        if notes[i].has_attr('xml:id') is False:\r\n",
        "            notes[i]['xml:id'] = 'note'+str(count)\r\n",
        "            count += 1\r\n",
        "\r\n",
        "    links = link_gr.find_all('link')\r\n",
        "\r\n",
        "    for i in range(len(links)):\r\n",
        "        if links[i].has_attr('target') is False:\r\n",
        "            links[i]['target'] = '#note'+str(cnt)\r\n",
        "            cnt += 1\r\n",
        "\r\n",
        "    dictionary = {'а':'a','б':'b','в':'v','г':'g','д':'d','е':'e','ё':'yo',\r\n",
        "          'ж':'zh','з':'z','и':'i','й':'i','к':'k','л':'l','м':'m','н':'n',\r\n",
        "          'о':'o','п':'p','р':'r','с':'s','т':'t','у':'u','ф':'f','х':'kh',\r\n",
        "          'ц':'c','ч':'ch','ш':'sh','щ':'sch','ъ':'','ы':'y','ь':'','э':'e',\r\n",
        "          'ю':'u','я':'ya', 'А':'A','Б':'B','В':'V','Г':'G','Д':'D','Е':'E','Ё':'YO',\r\n",
        "          'Ж':'ZH','З':'Z','И':'I','Й':'I','К':'K','Л':'L','М':'M','Н':'N',\r\n",
        "          'О':'O','П':'P','Р':'R','С':'S','Т':'T','У':'U','Ф':'F','Х':'KH',\r\n",
        "          'Ц':'C','Ч':'CH','Ш':'SH','Щ':'SCH','Ъ':'','Ы':'Y','Ь':'','Э':'E',\r\n",
        "          'Ю':'U','Я':'YA', ' ' : '_'}\r\n",
        "\r\n",
        "    title = re.sub(r'[/\\:*?''<>!«»—,]', '', title_main_tei.string)\r\n",
        "    for key in dictionary:\r\n",
        "        title = title.replace(key, dictionary[key])\r\n",
        "    title = title[:15]\r\n",
        "\r\n",
        "    # Сохраняем\r\n",
        "    file = open(new_directory + 'V3_'+ str(iter) + '_' + title + '.xml', 'w', encoding='utf8') # В зависимости от номера тома поменять цифру рядом с \"V\" (V1 - первый том)\r\n",
        "    file.write(soup_tei.prettify())\r\n",
        "    file.close()\r\n",
        "    #print(soup_tei.prettify())\r\n",
        "\r\n",
        "    iter += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vOrBGQtXawT"
      },
      "source": [
        " "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}