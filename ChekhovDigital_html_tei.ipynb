{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chekhov_Digital_HTML_TEI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz46TQKsaaUW"
      },
      "source": [
        "Для обработки опубликованных и изданных текстов А. П. Чехова. При обработке неизданных/неопубликованных документов в исходном файле (TEIdoc) изменить информацию внутри тегов \"isFinished\" (оконченные/неокончнные) и \"isPublished\" (опубликованные/неопубликованные).\r\n",
        "\r\n",
        "Исходные HTML-файлы должны быть размещены на гугл-диске (если они расположены в другом месте, поменять директорию. Переменные directory, new_directory).\r\n",
        "\r\n",
        "При обработке томов, содержащих только один жанр текста (например, том 11 - пьесы) заполнить в исходном файле (TEIdoc) тег \"textClass\" (тип текста)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-cd0OJ1hICV",
        "outputId": "c3ab6b6d-f9d6-441b-f312-af4019145b13"
      },
      "source": [
        "!pip install natasha\r\n",
        "# Для документов, расположенных на гугл-диске\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: natasha in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: slovnet>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from natasha) (0.5.0)\n",
            "Requirement already satisfied: ipymarkup>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from natasha) (0.9.0)\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.6/dist-packages (from natasha) (0.9.1)\n",
            "Requirement already satisfied: razdel>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from natasha) (0.5.0)\n",
            "Requirement already satisfied: navec>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from natasha) (0.10.0)\n",
            "Requirement already satisfied: yargy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from natasha) (0.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from slovnet>=0.3.0->natasha) (1.19.5)\n",
            "Requirement already satisfied: intervaltree>=3 in /usr/local/lib/python3.6/dist-packages (from ipymarkup>=0.8.0->natasha) (3.1.0)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2->natasha) (0.6.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from pymorphy2->natasha) (0.7.2)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.6/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.3.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvMsxPonolbD"
      },
      "source": [
        "import os\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "import re\r\n",
        "from pathlib import Path\r\n",
        "\r\n",
        "from natasha import (\r\n",
        "    Segmenter, MorphVocab,\r\n",
        "    NewsEmbedding, NewsMorphTagger, NewsSyntaxParser, NewsNERTagger,\r\n",
        "    NamesExtractor, DatesExtractor, MoneyExtractor, AddrExtractor,\r\n",
        "    PER, Doc\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j11YmK7ummoE"
      },
      "source": [
        "BASE_PATH = Path('drive/My Drive/Colab Notebooks/Transform_tei/HTML_TEI')\r\n",
        "Texts_HTML_PATH = BASE_PATH / 'texts_html'\r\n",
        "Texts_TEI_PATH = BASE_PATH / 'texts_tei'\r\n",
        "TEI_Preform_file = BASE_PATH / 'TEIdoc.xml'\r\n",
        "NOTES_Preform_PATH = BASE_PATH / 'notes_html'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnvquLWQ_TY7"
      },
      "source": [
        "your_name = 'Кудин Анастасией' #имя заполняющего"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A99LUQB7jswy"
      },
      "source": [
        "def open_with_soup(file_path, encoding):\r\n",
        "    with open(file_path,'r',encoding=encoding) as file:\r\n",
        "        content = file.read()\r\n",
        "    soup = BeautifulSoup(content, 'html.parser')\r\n",
        "    return soup\r\n",
        "\r\n",
        "\r\n",
        "def create_dir(directory):\r\n",
        "  if not os.path.exists(directory):\r\n",
        "    os.makedirs(directory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxUX5QrEZwtI"
      },
      "source": [
        "segmenter = Segmenter()\r\n",
        "morph_vocab = MorphVocab()\r\n",
        "\r\n",
        "emb = NewsEmbedding()\r\n",
        "morph_tagger = NewsMorphTagger(emb)\r\n",
        "syntax_parser = NewsSyntaxParser(emb)\r\n",
        "ner_tagger = NewsNERTagger(emb)\r\n",
        "\r\n",
        "names_extractor = NamesExtractor(morph_vocab)\r\n",
        "dates_extractor = DatesExtractor(morph_vocab)\r\n",
        "money_extractor = MoneyExtractor(morph_vocab)\r\n",
        "addr_extractor = AddrExtractor(morph_vocab)\r\n",
        "\r\n",
        "\r\n",
        "def extract_names(text):\r\n",
        "    doc = Doc(text)\r\n",
        "    doc.segment(segmenter)\r\n",
        "    doc.tag_morph(morph_tagger)\r\n",
        "    doc.parse_syntax(syntax_parser)\r\n",
        "    doc.tag_ner(ner_tagger)\r\n",
        "    for span in doc.spans:\r\n",
        "        if span.type == PER:\r\n",
        "            span.normalize(morph_vocab)\r\n",
        "            span.extract_fact(names_extractor)\r\n",
        "    names = [{'normal': _.normal, 'fio': _.fact.as_dict, 'start': _.start, 'end': _.stop} for _ in doc.spans if _.fact]\r\n",
        "    return names\r\n",
        "\r\n",
        "\r\n",
        "def extract_dates(text):\r\n",
        "    return list(dates_extractor(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xzLIJqoCRG5"
      },
      "source": [
        "class MetaSetter():\r\n",
        "    \"\"\"Класс с методами для заполнения метаинформации о произведении\"\"\"\r\n",
        "    def __init__(self, soup_html, soup_tei):\r\n",
        "        self.soup_html = soup_html\r\n",
        "        self.soup_tei = soup_tei\r\n",
        "\r\n",
        "\r\n",
        "    def fill_title(self):\r\n",
        "        \"\"\"Заполняет название\"\"\"\r\n",
        "        title_main_tei = self.soup_tei.find('title')\r\n",
        "        title_tag_html = self.soup_html.find_all('meta', attrs={'name':'title'})\r\n",
        "        title_main_tei.string = title_tag_html[0].get('content')\r\n",
        "        if len(title_tag_html) == 2: # Если есть подзаголовок\r\n",
        "            title_main_tei.string += f\" ({title_tag_html[1].get('content')})\"\r\n",
        "\r\n",
        "\r\n",
        "    def fill_description(self):\r\n",
        "        \"\"\"Заполняет описание текста\"\"\"\r\n",
        "        description_html = self.soup_html.find('div', class_='description')\r\n",
        "        full_bibl = self.soup_tei.find('biblfull').find('p')\r\n",
        "        full_bibl.string = description_html.text\r\n",
        "        self._description_html = description_html\r\n",
        "\r\n",
        "\r\n",
        "    def fill_transformator_name(self, transformator_name):\r\n",
        "        \"\"\"Заполняет имя того, кто преобразовал текст в TEI\"\"\"\r\n",
        "        name_resp_stmt = self.soup_tei.find('respstmt').find('persname')\r\n",
        "        name_resp_stmt.string = transformator_name\r\n",
        "\r\n",
        "\r\n",
        "    def fill_size_info(self):\r\n",
        "        \"\"\"Заполняет информацию об объеме произведения\"\"\"\r\n",
        "        extent_inf = self.soup_tei.find('extent')\r\n",
        "        # Получаем список номеров страниц\r\n",
        "        list_ids = [] \r\n",
        "        for tag in self.soup_html.find_all('span', class_='page') :\r\n",
        "            tag_page=tag.get('id')\r\n",
        "            list_ids.append(tag_page[2:])\r\n",
        "\r\n",
        "        # Считаем объем\r\n",
        "        volume = int(list_ids[-1]) - int(list_ids[0]) + 1\r\n",
        "        volume_str = str(volume)\r\n",
        "\r\n",
        "        # Формируем результирующую строку\r\n",
        "        if volume_str[-1] in ['5', '6', '7', '8', '9', '0'] or\\\r\n",
        "                (len(volume_str) == 2 and volume_str[-2] == '1'):\r\n",
        "            volume_f = volume_str + ' страниц'\r\n",
        "        elif volume_str[-1] == '1':\r\n",
        "            volume_f = volume_str + ' страница'\r\n",
        "        else:\r\n",
        "            volume_f = volume_str + ' страницы'\r\n",
        "\r\n",
        "        # Заполняем информацию об объеме в атрибутах тегов\r\n",
        "        tag_measure = self.soup_tei.new_tag('measure') \r\n",
        "        extent_inf.insert(0, tag_measure)\r\n",
        "\r\n",
        "        self.soup_tei.find('measure')['unit'] = 'pages'\r\n",
        "        self.soup_tei.find('measure')['quantity'] = volume_str\r\n",
        "\r\n",
        "        measure_inf = self.soup_tei.find('measure')\r\n",
        "        measure_inf.string = volume_f\r\n",
        "\r\n",
        "\r\n",
        "    def fill_publication_date(self):\r\n",
        "        \"\"\"Заполняет дату публикации произведения\"\"\"\r\n",
        "        publ_date = self.soup_tei.find('publicationstmt')\r\n",
        "        publ_date1 = publ_date.find('date')\r\n",
        "        date_1 = self.soup_html.find('meta', attrs={'name':'date'})\r\n",
        "        publ_date1.string = date_1.get('content')\r\n",
        "        publ_date.find('date')['when'] = date_1.get('content')\r\n",
        "\r\n",
        "\r\n",
        "    def fill_creation_date(self):\r\n",
        "        \"\"\"Заполняет дату создания произведения\"\"\"\r\n",
        "        date_cr = self.soup_tei.find('creation').find('date')\r\n",
        "        abz = self._description_html.find_all('p')\r\n",
        "        search = abz[-2].text\r\n",
        "\r\n",
        "        date_from_to = re.findall(r'\\d{4}—\\d{4}', search)\r\n",
        "        if len(date_from_to) > 0: # Если том создавался несколько лет\r\n",
        "            date_cr.string = date_from_to[0]\r\n",
        "            date_cr['from'] = date_from_to[0][:4]\r\n",
        "            date_cr['to'] = date_from_to[0][-4:]\r\n",
        "        else: # Если том создавался один год (5 и 6 тома)\r\n",
        "            date_when = re.findall(r'\\d{4}', search)[0]\r\n",
        "            date_cr['when'] = date_when\r\n",
        "            date_cr.string = date_when\r\n",
        "        self._abz = abz\r\n",
        "\r\n",
        "\r\n",
        "    def fill_edition_info(self):\r\n",
        "        \"\"\"Заполняет информацию об издании\"\"\"\r\n",
        "        edstmt = self._abz[0].text.split('//')\r\n",
        "        edstmt1 = edstmt[1].split('\\n')[0]\r\n",
        "        edition_stmt = self.soup_tei.find('editionstmt').find('p')\r\n",
        "        edition_stmt.string = edstmt1\r\n",
        "        self._edition_stmt = edition_stmt\r\n",
        "\r\n",
        "\r\n",
        "    def fill_volume_num(self):\r\n",
        "        \"\"\"Заполняет номер тома\"\"\"\r\n",
        "        volume = re.findall(r'Т. \\d+.', self._edition_stmt.string)\r\n",
        "        volume_n = re.findall(r'\\d+', volume[0])\r\n",
        "        bibl_sc = self.soup_tei.find('biblscope')\r\n",
        "        bibl_sc.string = 'Том ' + volume_n[0]\r\n",
        "\r\n",
        "\r\n",
        "    def fill_all_meta(self, transformator_name):\r\n",
        "        \"\"\"Полностью заполняет метаинформацию\"\"\"\r\n",
        "        #Порядок выполнения функций лучше не менять\r\n",
        "        self.fill_title()\r\n",
        "        self.fill_description()\r\n",
        "        self.fill_transformator_name(transformator_name)\r\n",
        "        self.fill_size_info()\r\n",
        "        self.fill_publication_date()\r\n",
        "        self.fill_creation_date()\r\n",
        "        self.fill_edition_info()\r\n",
        "        self.fill_volume_num()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbFZAQvBlsoc"
      },
      "source": [
        "class ExistenceSeter():\r\n",
        "    \"\"\"Класс с методами для разметки сущностей\"\"\"\r\n",
        "    \r\n",
        "    @staticmethod\r\n",
        "    def set_people(par_tag, location_text):\r\n",
        "        \"\"\"Расставляет теги имен\"\"\"\r\n",
        "\r\n",
        "        def pattern_repl_name_fio(name_part, name_info_fio, name_format):\r\n",
        "            \"\"\"Готовит шаблоны для замены\"\"\"\r\n",
        "            if name_part in name_info_fio:\r\n",
        "                pattern_start = name_info_fio[name_part]\r\n",
        "                pattern_end = r'.'\r\n",
        "                repl_end = r'.'\r\n",
        "                if len(name_info_fio[name_part]) != 1:\r\n",
        "                    try:\r\n",
        "                        pattern_start = name_info_fio[name_part][:-2]\r\n",
        "                    except:\r\n",
        "                        pattern_start = name_info_fio[name_part][:-1]\r\n",
        "                    pattern_end = r'(\\w*)'\r\n",
        "                    repl_end = r'\\g<1>'\r\n",
        "                return pattern_start + pattern_end, name_format.format(name_info_fio[name_part], pattern_start + repl_end)\r\n",
        "            return None\r\n",
        "\r\n",
        "        names = extract_names(str(par_tag.string))\r\n",
        "        person_format = '<PersName type=\"{0}\">{1}</PersName>'\r\n",
        "        name_format = '<forename xml:id=\"{0}\">{1}</forename>'\r\n",
        "        surname_format = '<surname xml:id=\"{0}\">{1}</surname>'\r\n",
        "        middlename_format = '<forename type=\"patronym\" xml:id=\"{0}\">{1}</forename>'\r\n",
        "        for name_info in names[::-1]:\r\n",
        "            person_part = par_tag.string[name_info['start']:name_info['end']]\r\n",
        "            patterns_repls = []\r\n",
        "            pattern_repl = pattern_repl_name_fio('first', name_info['fio'], name_format)\r\n",
        "            if pattern_repl is not None:\r\n",
        "                patterns_repls.append((*pattern_repl, False))\r\n",
        "\r\n",
        "            pattern_repl = pattern_repl_name_fio('last', name_info['fio'], surname_format)\r\n",
        "            if pattern_repl is not None:\r\n",
        "                patterns_repls.append((*pattern_repl, False))\r\n",
        "\r\n",
        "            pattern_repl = pattern_repl_name_fio('middle', name_info['fio'], middlename_format)\r\n",
        "            if pattern_repl is not None:\r\n",
        "                patterns_repls.append((*pattern_repl, False))\r\n",
        "\r\n",
        "            name_parts = re.split('\\s+', person_part)\r\n",
        "            for i in range(len(name_parts)):\r\n",
        "                for j in range(len(patterns_repls)):\r\n",
        "                    pattern, repl, used = patterns_repls[j]\r\n",
        "                    if used:\r\n",
        "                        continue\r\n",
        "                    if re.search(pattern, name_parts[i]):\r\n",
        "                        name_parts[i] = re.sub(pattern, repl, name_parts[i])\r\n",
        "                        patterns_repls[j] = (pattern, repl, True)\r\n",
        "                        break\r\n",
        "\r\n",
        "            new_person_part = person_format.format(location_text, ' '.join(name_parts))\r\n",
        "\r\n",
        "            par_tag.string = par_tag.string[:name_info['start']] +\\\r\n",
        "                            new_person_part +\\\r\n",
        "                            par_tag.string[name_info['end']:]\r\n",
        "    \r\n",
        "    @staticmethod\r\n",
        "    def set_dates(par_tag):\r\n",
        "        \"\"\"Расставляет теги дат\"\"\"\r\n",
        "\r\n",
        "        def set_date_part(res_lst, date_part_type):\r\n",
        "            if date_part_type:\r\n",
        "                res_lst.append(str(date_part_type))\r\n",
        "            else:\r\n",
        "                res_lst.append('')                \r\n",
        "\r\n",
        "        dates = extract_dates(str(par_tag.string))\r\n",
        "        date_format = '<date when=\"{0}\">{1}</date>'\r\n",
        "        for date_info in dates[::-1]:\r\n",
        "            date_part = par_tag.string[date_info.start:date_info.stop]\r\n",
        "            res_lst = []\r\n",
        "            set_date_part(res_lst, date_info.fact.year)\r\n",
        "            set_date_part(res_lst, date_info.fact.month)\r\n",
        "            set_date_part(res_lst, date_info.fact.day)\r\n",
        "            new_date_part = date_format.format('-'.join(res_lst), date_part)\r\n",
        "            par_tag.string = par_tag.string[:date_info.start] +\\\r\n",
        "                            new_date_part +\\\r\n",
        "                            par_tag.string[date_info.stop:]\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def process_all_existences(par_tag, location_text):\r\n",
        "        \"\"\"Полная обработка сущностей\"\"\"\r\n",
        "        ExistenceSeter.set_people(par_tag, location_text)\r\n",
        "        ExistenceSeter.set_dates(par_tag)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWzQDykgMiRg"
      },
      "source": [
        "class TextSetter():\r\n",
        "    \"\"\"Класс с методами для заполнения текста произведения\"\"\"\r\n",
        "\r\n",
        "    def __init__(self, soup_html, soup_tei, soup_notes_html):\r\n",
        "        self.soup_html = soup_html\r\n",
        "        self.soup_tei = soup_tei\r\n",
        "        self.soup_notes_html = soup_notes_html\r\n",
        "\r\n",
        "\r\n",
        "    def _help_get_id(self):\r\n",
        "        \"\"\"Получает id нашего текста\"\"\"\r\n",
        "        self._text_id = self.soup_html.find_all('a')[1].get('href').split('#')[1]\r\n",
        "\r\n",
        "\r\n",
        "    def _help_find_text_tags(self):\r\n",
        "        \"\"\"Создает переменные-теги, отвечающие за произведение\"\"\"\r\n",
        "        self._pars = self.soup_html.find_all(['p', 'span', 'img'])\r\n",
        "        self._body = self.soup_tei.select('text body')[0]\r\n",
        "        first_page = self.soup_html.find('span', class_='page').get('id')[2:]\r\n",
        "        self._pb_tag = self.soup_tei.new_tag('pb', attrs={'n':first_page})\r\n",
        "\r\n",
        "\r\n",
        "    def process_page(self, cur_tag):\r\n",
        "        \"\"\"Обрабатывает абзац-страницу\"\"\"\r\n",
        "        cur_page = cur_tag.get('id')[2:]\r\n",
        "        self._pb_tag = self.soup_tei.new_tag('pb', attrs={'n':cur_page})\r\n",
        "        self._pb_tag.string = cur_tag.get('id')[2:]\r\n",
        "        self._body.append(self._pb_tag)\r\n",
        "\r\n",
        "\r\n",
        "    def move_text_with_notes(self, tag_to, tag_from):\r\n",
        "        \"\"\"Переносит содержиомое тега с сохранением сносок\"\"\"\r\n",
        "        def help_recursive(tag_from):\r\n",
        "            if isinstance(tag_from, str):\r\n",
        "                return tag_from\r\n",
        "            res = ''\r\n",
        "            note_format = '<note xml:id={0}>{1}</note>'\r\n",
        "            for tag_part in tag_from.contents:\r\n",
        "                if isinstance(tag_part, str):\r\n",
        "                    res += tag_part\r\n",
        "                elif tag_part.name == 'a':\r\n",
        "                    if tag_part.has_attr('class') and tag_part['class'][0] == 'footnote':\r\n",
        "                        res += note_format.format(tag_part['href'][1:], tag_part.text)\r\n",
        "                    elif tag_part.has_attr('href') and re.match(r'#$\\S*', tag_part['href'][0]) is None:\r\n",
        "                        res += note_format.format('external_link', tag_part.text)\r\n",
        "                elif tag_part.name not in ['p', 'div']:\r\n",
        "                    res += help_recursive(tag_part)\r\n",
        "            return res\r\n",
        "\r\n",
        "        tag_to.string = help_recursive(tag_from)\r\n",
        "        \r\n",
        "\r\n",
        "    def process_image(self, cur_tag):\r\n",
        "        \"\"\"Обрабатывает абзац-изображение\"\"\"\r\n",
        "        fig_tag = self.soup_tei.new_tag('figure')\r\n",
        "        self._pb_tag.append(fig_tag)\r\n",
        "        graph_tag = self.soup_tei.new_tag('graphic')\r\n",
        "        fig_tag.append(graph_tag)\r\n",
        "        get_href = cur_tag.get('src').split('/')\r\n",
        "        fig_tag.find('graphic')['url'] = f'http://feb-web.ru/feb/chekhov/{get_href[-2]}/{get_href[-1]}'\r\n",
        "        desc_tag = self.soup_tei.new_tag('figDesc')\r\n",
        "        fig_tag.append(desc_tag)\r\n",
        "        #desc_tag.string = cur_tag.get('alt')\r\n",
        "        self.move_text_with_notes(desc_tag, cur_tag.get('alt'))\r\n",
        "        ExistenceSeter.process_all_existences(desc_tag, 'figure')\r\n",
        "\r\n",
        "    \r\n",
        "    def process_subheading(self, cur_tag):\r\n",
        "        \"\"\"Обрабатывает абзац-подзаголовок\"\"\"\r\n",
        "        new_p = self.soup_tei.new_tag('p')\r\n",
        "        self._pb_tag.append(new_p)\r\n",
        "        tag_headline = self.soup_tei.new_tag('head')\r\n",
        "        new_p.append(tag_headline)\r\n",
        "        self._body.find('head')['rend'] = 'center'\r\n",
        "        self._body.find('head')['type'] = 'subtitle'\r\n",
        "        #tag_headline.string = cur_tag.text.split('\\n')[0]\r\n",
        "        self.move_text_with_notes(tag_headline, cur_tag)\r\n",
        "        ExistenceSeter.process_all_existences(tag_headline, 'subtitle')\r\n",
        "\r\n",
        "\r\n",
        "    def process_heading(self, cur_tag):\r\n",
        "        \"\"\"Обрабатывает абзац-заголовок\"\"\"\r\n",
        "        new_p = self.soup_tei.new_tag('p')\r\n",
        "        self._pb_tag.append(new_p)\r\n",
        "        tag_headline = self.soup_tei.new_tag('head')\r\n",
        "        new_p.append(tag_headline)\r\n",
        "        self._body.find('head')['rend'] = 'center'\r\n",
        "        tag_hi = self.soup_tei.new_tag('hi') \r\n",
        "        tag_headline.append(tag_hi)\r\n",
        "        self._body.find('hi')['rend'] = 'strong'\r\n",
        "        #tag_hi.string = cur_tag.text.split('\\n')[0]\r\n",
        "        self.move_text_with_notes(tag_hi, cur_tag)\r\n",
        "        ExistenceSeter.process_all_existences(tag_hi, 'title')\r\n",
        "\r\n",
        "\r\n",
        "    def process_epigraph(self, cur_tag):\r\n",
        "        \"\"\"Обрабатывает абзац-эпиграф\"\"\"\r\n",
        "        new_p = self.soup_tei.new_tag('p')\r\n",
        "        self._pb_tag.append(new_p)\r\n",
        "        tag_epigraph = self.soup_tei.new_tag('epigraph')\r\n",
        "        new_p.append(tag_epigraph)\r\n",
        "        self._body.find('epigraph')['rend'] = 'right'\r\n",
        "        #tag_epigraph.string = cur_tag.text\r\n",
        "        self.move_text_with_notes(tag_epigraph, cur_tag)\r\n",
        "        ExistenceSeter.process_all_existences(tag_epigraph, 'epigraph')\r\n",
        "\r\n",
        "\r\n",
        "    def process_greeting(self, cur_tag):\r\n",
        "        \"\"\"Обрабатывает абзац-приветствие/обращение\"\"\"\r\n",
        "        new_p = self.soup_tei.new_tag('p')\r\n",
        "        self._pb_tag.append(new_p)\r\n",
        "        tag_salute = self.soup_tei.new_tag('salute')\r\n",
        "        new_p.append(tag_salute)\r\n",
        "        #tag_salute.string = cur_tag.text.split('\\n')[0]\r\n",
        "        self.move_text_with_notes(tag_salute, cur_tag)\r\n",
        "        ExistenceSeter.process_all_existences(tag_salute, 'salute')\r\n",
        "\r\n",
        "\r\n",
        "    def process_signature(self, cur_tag):\r\n",
        "        \"\"\"Обрабатывает абзац-подпись\"\"\"\r\n",
        "        new_p = self.soup_tei.new_tag('p')\r\n",
        "        self._pb_tag.append(new_p)\r\n",
        "        tag_podp = self.soup_tei.new_tag('signed')\r\n",
        "        new_p.append(tag_podp)\r\n",
        "        #tag_podp.string = cur_tag.text.split('\\n')[0]\r\n",
        "        self.move_text_with_notes(tag_podp, cur_tag)\r\n",
        "        ExistenceSeter.process_all_existences(tag_podp, 'signed')\r\n",
        "\r\n",
        "\r\n",
        "    def process_text(self, cur_tag):\r\n",
        "        \"\"\"Обрабатывает абзац-текст\"\"\"\r\n",
        "        new_p = self.soup_tei.new_tag('p')\r\n",
        "        self._pb_tag.append(new_p) \r\n",
        "        #new_p.string = cur_tag.text.split('\\n')[0]\r\n",
        "        self.move_text_with_notes(new_p, cur_tag)\r\n",
        "        ExistenceSeter.process_all_existences(new_p, 'text')\r\n",
        "\r\n",
        "\r\n",
        "    def process_notes(self):\r\n",
        "        \"\"\"Обработка примечаний\"\"\"\r\n",
        "        self._link_tag = self.soup_tei.new_tag('linkGrp')\r\n",
        "        self._body.append(self._link_tag)\r\n",
        "        self._link_tag.string = 'Примечания'\r\n",
        "        try:\r\n",
        "            first_tag = self.soup_notes_html.find('h4', attrs={'id':self._text_id})\r\n",
        "            next_tag = first_tag.find_next('h4')\r\n",
        "\r\n",
        "            note_tag = self.soup_tei.new_tag('link')\r\n",
        "            note_tag['target'] = 'external_snos'\r\n",
        "            self._link_tag.append(note_tag)\r\n",
        "        except:\r\n",
        "            return\r\n",
        "        all_tags = first_tag.find_all_next()\r\n",
        "        for cur_tag in all_tags:\r\n",
        "            if cur_tag == next_tag:\r\n",
        "                break\r\n",
        "            if cur_tag.has_attr('class') and re.match(r'small\\S*|prim\\S*|text\\S*|txt\\S*|mtext\\S*', cur_tag['class'][0]) is not None:\r\n",
        "                if cur_tag.text[:4].lstrip() == 'Стр.' or cur_tag.text[:3].lstrip() == '...':\r\n",
        "                    note_tag1 = self.soup_tei.new_tag('link')\r\n",
        "                    note_tag1['target'] = 'external_snos'\r\n",
        "                    self._link_tag.append(note_tag1)\r\n",
        "                    new_p = self.soup_tei.new_tag('p')\r\n",
        "                    note_tag1.append(new_p)\r\n",
        "                    new_p.string = cur_tag.text.split('\\n')[0]\r\n",
        "                    ExistenceSeter.process_all_existences(new_p, 'note')\r\n",
        "                else:\r\n",
        "                    new_p = self.soup_tei.new_tag('p')\r\n",
        "                    note_tag.append(new_p)\r\n",
        "                    new_p.string = cur_tag.text.split('\\n')[0]\r\n",
        "                    ExistenceSeter.process_all_existences(new_p, 'note')                    \r\n",
        "                \r\n",
        "            \r\n",
        "    def process_snos(self):\r\n",
        "        \"\"\"Получает примечания внутри произведения из раздела сноски\"\"\"\r\n",
        "        text = self.soup_html.find_all('p', class_=['snos', 'snoska'])\r\n",
        "        for a in text:\r\n",
        "            note_tag = self.soup_tei.new_tag('link')\r\n",
        "            note_tag['target'] = a['id']\r\n",
        "            self._link_tag.append(note_tag)\r\n",
        "            note_tag.string = re.sub('^\\d+ ', '', a.text)\r\n",
        "            ExistenceSeter.process_all_existences(note_tag, 'note')\r\n",
        "\r\n",
        "\r\n",
        "    def link_notes_in_text(self):\r\n",
        "        \"\"\"Присваиваем примечаниям id\"\"\"\r\n",
        "        notes = self.soup_tei.find('body').find_all('note')\r\n",
        "        linkgrp = self.soup_tei.find('linkgrp')\r\n",
        "        links_snos = linkgrp.find_all('link', target=lambda x: x != 'external_snos')\r\n",
        "        links_external = linkgrp.find_all('link', target='external_snos')\r\n",
        "        for note in notes:\r\n",
        "            if note['xml:id'] == 'external_link':\r\n",
        "                for i_link in range(len(links_external)-1, -1,-1):\r\n",
        "                    if links_external[i_link].text.find(note.text.strip()) != -1:\r\n",
        "                        note['xml:id'] = f'note{i_link+1}'\r\n",
        "                        break\r\n",
        "                    note['xml:id'] = 'note1'\r\n",
        "            else:\r\n",
        "                for i_link in range(len(links_snos)):\r\n",
        "                    if note['xml:id'] == links_snos[i_link]['target']:\r\n",
        "                        note['xml:id'] = 'note' + str(i_link+1+len(links_external))\r\n",
        "                        break\r\n",
        "\r\n",
        "        for i_link in range(len(links_external)):\r\n",
        "            links_external[i_link]['target'] = f'#note{i_link+1}'\r\n",
        "\r\n",
        "        for i_link in range(len(links_snos)):\r\n",
        "            links_snos[i_link]['target'] = f'#note{i_link+1+len(links_external)}'\r\n",
        "\r\n",
        "\r\n",
        "    def fill_all_text(self):\r\n",
        "        \"\"\"Полная обработка текста\"\"\"\r\n",
        "        self._help_get_id()\r\n",
        "        self._help_find_text_tags()\r\n",
        "\r\n",
        "        for cur_tag in self._pars[1:]:\r\n",
        "            if cur_tag.has_attr('class') and cur_tag['class'][0] == 'page': # Если это страница\r\n",
        "                self.process_page(cur_tag)\r\n",
        "            elif cur_tag.has_attr('alt'): # Если это изображение\r\n",
        "                self.process_image(cur_tag)\r\n",
        "            elif cur_tag.has_attr('class') and re.match(r'zg\\S*', cur_tag['class'][0]) is not None: # Если это подзаголовок\r\n",
        "                self.process_subheading(cur_tag)\r\n",
        "            elif cur_tag.has_attr('class') and re.match(r'tit\\S*|zag\\S*', cur_tag['class'][0]) is not None: # Если это заголовок\r\n",
        "                self.process_heading(cur_tag)\r\n",
        "            elif cur_tag.has_attr('class') and re.match(r'epig\\S*', cur_tag['class'][0]) is not None: # Если это эпиграф\r\n",
        "                self.process_epigraph(cur_tag)\r\n",
        "            elif cur_tag.has_attr('class') and re.match(r'obraw\\S*', cur_tag['class'][0]) is not None: # Если это приветствие/обращение (в письме)\r\n",
        "                self.process_greeting(cur_tag)\r\n",
        "            elif cur_tag.has_attr('class') and re.match(r'podp\\S*', cur_tag['class'][0]) is not None: # Если это подпись (в письме)\r\n",
        "                self.process_signature(cur_tag)\r\n",
        "            elif cur_tag.has_attr('class') and re.match(r'text\\S*|curs\\S*|small\\S*|vis\\S*|center\\S*', cur_tag['class'][0]) is not None: # Если это текст\r\n",
        "                self.process_text(cur_tag)\r\n",
        "\r\n",
        "        # Переносим сноски\r\n",
        "        self.process_notes()\r\n",
        "\r\n",
        "        # Получаем примечания внутри произведения из раздела сноски\r\n",
        "        self.process_snos()\r\n",
        "\r\n",
        "        #исправляем возможные ошибки\r\n",
        "        tei_doc = str(self.soup_tei.prettify()[2:])\r\n",
        "        tei_doc = tei_doc.replace('&lt;', r'<')\r\n",
        "        tei_doc = tei_doc.replace('&gt;', r'>')\r\n",
        "        self.soup_tei = BeautifulSoup(tei_doc, 'html.parser')\r\n",
        "\r\n",
        "        # Присваиваем примечаниям id\r\n",
        "        self.link_notes_in_text()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKqjeY26r-Gk"
      },
      "source": [
        "dictionary = {'а':'a','б':'b','в':'v','г':'g','д':'d','е':'e','ё':'yo',\r\n",
        "        'ж':'zh','з':'z','и':'i','й':'i','к':'k','л':'l','м':'m','н':'n',\r\n",
        "        'о':'o','п':'p','р':'r','с':'s','т':'t','у':'u','ф':'f','х':'kh',\r\n",
        "        'ц':'c','ч':'ch','ш':'sh','щ':'sch','ъ':'','ы':'y','ь':'','э':'e',\r\n",
        "        'ю':'u','я':'ya', 'А':'A','Б':'B','В':'V','Г':'G','Д':'D','Е':'E','Ё':'YO',\r\n",
        "        'Ж':'ZH','З':'Z','И':'I','Й':'I','К':'K','Л':'L','М':'M','Н':'N',\r\n",
        "        'О':'O','П':'P','Р':'R','С':'S','Т':'T','У':'U','Ф':'F','Х':'KH',\r\n",
        "        'Ц':'C','Ч':'CH','Ш':'SH','Щ':'SCH','Ъ':'','Ы':'Y','Ь':'','Э':'E',\r\n",
        "        'Ю':'U','Я':'YA', ' ' : '_'}\r\n",
        "\r\n",
        "def save_tei(soup_tei, save_dir, file_num):\r\n",
        "    title = re.sub(r'[/\\:*?''<>!«»—,]', '', soup_tei.find('title').string.strip())\r\n",
        "    for key in dictionary:\r\n",
        "        title = title.replace(key, dictionary[key])\r\n",
        "    title = title[:15]\r\n",
        "\r\n",
        "    #В зависимости от номера тома поменять цифру рядом с \"V\"\r\n",
        "    with open(os.path.join(save_dir, f'V{volume_num}_{file_num}_{title}.xml'), 'w', encoding='utf8') as file: \r\n",
        "        file.write(soup_tei.prettify())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJBhCNdEl5Hj"
      },
      "source": [
        "for volume_num in range(1, 4):\r\n",
        "    #volume_num = 2\r\n",
        "    directory_html = Texts_HTML_PATH / str(volume_num)\r\n",
        "    directory_tei = Texts_TEI_PATH / str(volume_num)\r\n",
        "    create_dir(directory_tei)\r\n",
        "    note_file = NOTES_Preform_PATH / f'{str(volume_num)}.html'\r\n",
        "    \r\n",
        "    print(f'Том {volume_num} обрабатывается')\r\n",
        "    file_num = 1\r\n",
        "    for filename in os.listdir(directory_html):\r\n",
        "        #filename = '56_Mamasha.html'\r\n",
        "        print(filename)\r\n",
        "        soup_html = open_with_soup(directory_html / filename, 'windows-1251')\r\n",
        "        soup_tei = open_with_soup(TEI_Preform_file, 'utf8')\r\n",
        "        soup_notes_html = open_with_soup(note_file, 'windows-1251')\r\n",
        "\r\n",
        "        #заполянем мета-информацию\r\n",
        "        meta_setter = MetaSetter(soup_html, soup_tei)\r\n",
        "        meta_setter.fill_all_meta(your_name)\r\n",
        "\r\n",
        "        #заполняем текст и сноски\r\n",
        "        text_setter = TextSetter(soup_html, soup_tei, soup_notes_html)\r\n",
        "        text_setter.fill_all_text()\r\n",
        "\r\n",
        "        soup_tei = text_setter.soup_tei\r\n",
        "\r\n",
        "        #сохраняем\r\n",
        "        save_tei(soup_tei, directory_tei, file_num)\r\n",
        "        file_num += 1\r\n",
        "    print('------------')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}